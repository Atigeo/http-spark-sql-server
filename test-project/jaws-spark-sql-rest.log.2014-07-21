2014-07-21 15:22:22 ScalaTest-main-running-SharkUtilsTest Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.20.226 instead (on interface tun0)
2014-07-21 15:22:22 ScalaTest-main-running-SharkUtilsTest Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest SecurityManager [INFO] Changing view acls to: root
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 15:22:27 spark-akka.actor.default-dispatcher-2 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 15:22:27 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Starting remoting
2014-07-21 15:22:27 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.20.226:56354]
2014-07-21 15:22:27 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.20.226:56354]
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721152227-f6fb
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest MemoryStore [INFO] MemoryStore started with capacity 2.1 GB.
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest ConnectionManager [INFO] Bound socket to port 43215 with id = ConnectionManagerId(5.5.20.226,43215)
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 15:22:27 spark-akka.actor.default-dispatcher-5 BlockManagerInfo [INFO] Registering block manager 5.5.20.226:43215 with 2.1 GB RAM
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest HttpServer [INFO] Starting HTTP Server
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest Server [INFO] jetty-7.6.8.v20121106
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest AbstractConnector [INFO] Started SocketConnector@0.0.0.0:46753
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest HttpBroadcast [INFO] Broadcast server started at http://5.5.20.226:46753
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest HttpFileServer [INFO] HTTP File server directory is /tmp/spark-b20d2dd3-0975-49c7-a08e-1b56b5454cd5
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest HttpServer [INFO] Starting HTTP Server
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest Server [INFO] jetty-7.6.8.v20121106
2014-07-21 15:22:27 ScalaTest-main-running-SharkUtilsTest AbstractConnector [INFO] Started SocketConnector@0.0.0.0:54899
2014-07-21 18:01:36 main JawsController$ [INFO] Initializing...
2014-07-21 18:01:51 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:01:51 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:01:56 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:01:56 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:01:57 spark-akka.actor.default-dispatcher-4 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:01:57 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Starting remoting
2014-07-21 18:01:57 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:60814]
2014-07-21 18:01:57 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:60814]
2014-07-21 18:01:57 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:01:57 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:01:57 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721180157-969a
2014-07-21 18:01:57 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:01:57 main ConnectionManager [INFO] Bound socket to port 54082 with id = ConnectionManagerId(5.5.21.123,54082)
2014-07-21 18:01:57 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:01:57 spark-akka.actor.default-dispatcher-4 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:54082 with 1061.8 MB RAM
2014-07-21 18:01:57 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:01:57 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:01:58 main Server [INFO] jetty-7.6.8.v20121106
2014-07-21 18:01:58 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:58922
2014-07-21 18:01:58 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:58922
2014-07-21 18:01:58 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-d1dd6f9a-24bd-44aa-bfe8-af25b6b0e3e7
2014-07-21 18:01:58 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:01:58 main Server [INFO] jetty-7.6.8.v20121106
2014-07-21 18:01:58 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:49757
2014-07-21 18:09:36 main JawsController$ [INFO] Initializing...
2014-07-21 18:09:36 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:09:36 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:09:41 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:09:41 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:09:41 spark-akka.actor.default-dispatcher-4 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:09:41 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Starting remoting
2014-07-21 18:09:42 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:42113]
2014-07-21 18:09:42 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:42113]
2014-07-21 18:09:42 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:09:42 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:09:42 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721180942-5b53
2014-07-21 18:09:42 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:09:42 main ConnectionManager [INFO] Bound socket to port 45197 with id = ConnectionManagerId(5.5.21.123,45197)
2014-07-21 18:09:42 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:09:42 spark-akka.actor.default-dispatcher-3 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:45197 with 1061.8 MB RAM
2014-07-21 18:09:42 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:09:42 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:09:42 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:09:42 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:60208
2014-07-21 18:09:42 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:60208
2014-07-21 18:09:42 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-1c433332-9009-4442-8d93-ce6056c8fd57
2014-07-21 18:09:42 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:09:42 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:09:42 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:58552
2014-07-21 18:09:47 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:09:47 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:09:47 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:09:47 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:09:47 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:58552/jars/test-app.jar with timestamp 1405955387989
2014-07-21 18:09:48 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:09:48 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:09:48 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:09:48 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721150951-0000
2014-07-21 18:09:48 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:10:22 main JawsController$ [INFO] Initializing...
2014-07-21 18:10:31 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:10:31 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:10:36 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:10:36 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:10:36 spark-akka.actor.default-dispatcher-4 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:10:36 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Starting remoting
2014-07-21 18:10:36 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:41399]
2014-07-21 18:10:36 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:41399]
2014-07-21 18:10:36 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:10:36 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:10:36 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721181036-29bf
2014-07-21 18:10:36 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:10:36 main ConnectionManager [INFO] Bound socket to port 37401 with id = ConnectionManagerId(5.5.21.123,37401)
2014-07-21 18:10:36 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:10:36 spark-akka.actor.default-dispatcher-4 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:37401 with 1061.8 MB RAM
2014-07-21 18:10:36 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:10:36 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:10:36 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:10:36 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:43723
2014-07-21 18:10:36 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:43723
2014-07-21 18:10:36 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-a6dad727-669b-4f1f-889e-d7c71eccc3ec
2014-07-21 18:10:36 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:10:36 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:10:36 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:50684
2014-07-21 18:10:42 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:10:42 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:10:42 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:10:42 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:10:42 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:50684/jars/test-app.jar with timestamp 1405955442405
2014-07-21 18:10:42 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:10:42 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:10:43 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:10:43 spark-akka.actor.default-dispatcher-3 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721151045-0001
2014-07-21 18:10:43 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Executor added: app-20140721151045-0001/0 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:10:43 spark-akka.actor.default-dispatcher-3 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151045-0001/0 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:10:43 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Executor added: app-20140721151045-0001/1 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:10:43 spark-akka.actor.default-dispatcher-3 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151045-0001/1 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:10:43 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721151045-0001/0 is now RUNNING
2014-07-21 18:10:43 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Executor updated: app-20140721151045-0001/1 is now RUNNING
2014-07-21 18:10:43 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:12:54 main JawsController$ [INFO] Initializing...
2014-07-21 18:12:59 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:12:59 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:13:04 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:13:04 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:13:04 spark-akka.actor.default-dispatcher-4 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:13:04 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Starting remoting
2014-07-21 18:13:04 spark-akka.actor.default-dispatcher-2 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:60096]
2014-07-21 18:13:04 spark-akka.actor.default-dispatcher-2 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:60096]
2014-07-21 18:13:04 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:13:04 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:13:04 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721181304-84e9
2014-07-21 18:13:04 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:13:05 main ConnectionManager [INFO] Bound socket to port 46315 with id = ConnectionManagerId(5.5.21.123,46315)
2014-07-21 18:13:05 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:13:05 spark-akka.actor.default-dispatcher-4 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:46315 with 1061.8 MB RAM
2014-07-21 18:13:05 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:13:05 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:13:05 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:13:05 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:37760
2014-07-21 18:13:05 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:37760
2014-07-21 18:13:05 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-e88ad4ef-e303-43c4-8c40-6531c36a1e5d
2014-07-21 18:13:05 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:13:05 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:13:05 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:50629
2014-07-21 18:13:10 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:13:10 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:13:10 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:13:10 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:13:10 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:50629/jars/test-app.jar with timestamp 1405955590827
2014-07-21 18:13:10 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:13:10 spark-akka.actor.default-dispatcher-12 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:13:11 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:13:11 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721151313-0002
2014-07-21 18:13:11 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor added: app-20140721151313-0002/0 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:13:11 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151313-0002/0 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:13:11 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor added: app-20140721151313-0002/1 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:13:11 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151313-0002/1 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:13:11 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721151313-0002/0 is now RUNNING
2014-07-21 18:13:11 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:13:11 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:13:11 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721151313-0002/1 is now RUNNING
2014-07-21 18:13:11 main ParseDriver [INFO] Parse Completed
2014-07-21 18:13:12 main Analyzer [INFO] Max iterations (2) reached for batch MultiInstanceRelations
2014-07-21 18:13:12 main Analyzer [INFO] Max iterations (2) reached for batch CaseInsensitiveAttributeReferences
2014-07-21 18:13:12 main Analyzer [INFO] Max iterations (2) reached for batch Check Analysis
2014-07-21 18:13:12 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Add exchange
2014-07-21 18:13:12 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Prepare Expressions
2014-07-21 18:13:12 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=Driver.run>
2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=TimeToSubmit>
2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=compile>
2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=parse>
2014-07-21 18:13:12 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:13:12 main ParseDriver [INFO] Parse Completed
2014-07-21 18:13:12 main Driver [INFO] </PERFLOG method=parse start=1405955592386 end=1405955592387 duration=1>
2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=semanticAnalyze>
2014-07-21 18:13:12 main Driver [INFO] Semantic Analysis Completed
2014-07-21 18:13:12 main Driver [INFO] </PERFLOG method=semanticAnalyze start=1405955592387 end=1405955592493 duration=106>
2014-07-21 18:13:12 main ListSinkOperator [INFO] Initializing Self 0 OP
2014-07-21 18:13:12 main ListSinkOperator [INFO] Operator 0 OP initialized
2014-07-21 18:13:12 main ListSinkOperator [INFO] Initialization Done 0 OP
2014-07-21 18:13:12 main Driver [INFO] Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
2014-07-21 18:13:12 main Driver [INFO] </PERFLOG method=compile start=1405955592364 end=1405955592560 duration=196>
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:host.name=ema-Latitude-E6530
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:java.version=1.7.0_51
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:java.vendor=Oracle Corporation
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:java.home=/usr/lib/jvm/jdk1.7.0/jre
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:java.class.path=/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/classes:/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-classes:/root/.m2/repository/io/spray/spray-client/1.2.1/spray-client-1.2.1.jar:/root/.m2/repository/io/spray/spray-http/1.2.1/spray-http-1.2.1.jar:/root/.m2/repository/io/spray/spray-httpx/1.2.1/spray-httpx-1.2.1.jar:/root/.m2/repository/org/jvnet/mimepull/mimepull/1.9.4/mimepull-1.9.4.jar:/root/.m2/repository/io/spray/spray-util/1.2.1/spray-util-1.2.1.jar:/root/.m2/repository/org/scalamock/scalamock-scalatest-support_2.10/3.1.RC1/scalamock-scalatest-support_2.10-3.1.RC1.jar:/root/.m2/repository/org/scalamock/scalamock-core_2.10/3.1.RC1/scalamock-core_2.10-3.1.RC1.jar:/root/.m2/repository/org/scala-lang/scala-reflect/2.10.0/scala-reflect-2.10.0.jar:/root/.m2/repository/org/scalatest/scalatest_2.10/2.0/scalatest_2.10-2.0.jar:/root/.m2/repository/junit/junit/4.4/junit-4.4.jar:/root/.m2/repository/io/spray/spray-routing/1.2.1/spray-routing-1.2.1.jar:/root/.m2/repository/com/chuusai/shapeless_2.10/1.2.4/shapeless_2.10-1.2.4.jar:/root/.m2/repository/io/spray/spray-can/1.2.1/spray-can-1.2.1.jar:/root/.m2/repository/io/spray/spray-io/1.2.1/spray-io-1.2.1.jar:/root/.m2/repository/io/spray/spray-caching/1.2.1/spray-caching-1.2.1.jar:/root/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.3/jsr305-2.0.3.jar:/root/.m2/repository/org/tachyonproject/tachyon/0.4.1-thrift/tachyon-0.4.1-thrift.jar:/root/.m2/repository/org/apache/ant/ant/1.9.0/ant-1.9.0.jar:/root/.m2/repository/org/apache/ant/ant-launcher/1.9.0/ant-launcher-1.9.0.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jsp/7.6.8.v20121106/jetty-jsp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp/2.1.0.v201105211820/javax.servlet.jsp-2.1.0.v201105211820.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.jasper.glassfish/2.1.0.v201110031002/org.apache.jasper.glassfish-2.1.0.v201110031002.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp.jstl/1.2.0.v201105211821/javax.servlet.jsp.jstl-1.2.0.v201105211821.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.taglibs.standard.glassfish/1.2.0.v201112081803/org.apache.taglibs.standard.glassfish-1.2.0.v201112081803.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.el/2.1.0.v201105211819/javax.el-2.1.0.v201105211819.jar:/root/.m2/repository/org/eclipse/jetty/orbit/com.sun.el/1.0.0.v201105211818/com.sun.el-1.0.0.v201105211818.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.eclipse.jdt.core/3.7.1/org.eclipse.jdt.core-3.7.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-webapp/7.6.8.v20121106/jetty-webapp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-xml/7.6.8.v20121106/jetty-xml-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-servlet/7.6.8.v20121106/jetty-servlet-7.6.8.v20121106.jar:/root/.m2/repository/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.2/slf4j-log4j12-1.7.2.jar:/root/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/.m2/repository/org/apache/commons/commons-lang3/3.0/commons-lang3-3.0.jar:/root/.m2/repository/org/apache/curator/curator-recipes/2.1.0-incubating/curator-recipes-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-framework/2.1.0-incubating/curator-framework-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-client/2.1.0-incubating/curator-client-2.1.0-incubating.jar:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/root/.m2/repository/org/java-websocket/Java-WebSocket/1.3.0/Java-WebSocket-1.3.0.jar:/root/.m2/repository/org/apache/spark/spark-core_2.10/1.0.1/spark-core_2.10-1.0.1.jar:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/root/.m2/repository/commons-codec/commons-codec/1.3/commons-codec-1.3.jar:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-plus/8.1.14.v20131031/jetty-plus-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.transaction/1.1.1.v201105210645/javax.transaction-1.1.1.v201105210645.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jndi/8.1.14.v20131031/jetty-jndi-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.mail.glassfish/1.4.1.v201005082020/javax.mail.glassfish-1.4.1.v201005082020.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.activation/1.1.0.v201105071233/javax.activation-1.1.0.v201105071233.jar:/root/.m2/repository/org/eclipse/jetty/jetty-security/8.1.14.v20131031/jetty-security-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/root/.m2/repository/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar:/root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/root/.m2/repository/org/slf4j/jul-to-slf4j/1.7.5/jul-to-slf4j-1.7.5.jar:/root/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.5/jcl-over-slf4j-1.7.5.jar:/root/.m2/repository/com/ning/compress-lzf/1.0.0/compress-lzf-1.0.0.jar:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/root/.m2/repository/com/twitter/chill_2.10/0.3.6/chill_2.10-0.3.6.jar:/root/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/.m2/repository/com/twitter/chill-java/0.3.6/chill-java-0.3.6.jar:/root/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/root/.m2/repository/org/spark-project/akka/akka-remote_2.10/2.2.3-shaded-protobuf/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/spark-project/akka/akka-actor_2.10/2.2.3-shaded-protobuf/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/com/typesafe/config/1.0.2/config-1.0.2.jar:/root/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar:/root/.m2/repository/org/spark-project/protobuf/protobuf-java/2.4.1-shaded/protobuf-java-2.4.1-shaded.jar:/root/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/root/.m2/repository/org/spark-project/akka/akka-slf4j_2.10/2.2.3-shaded-protobuf/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.6/json4s-jackson_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-core_2.10/3.2.6/json4s-core_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-ast_2.10/3.2.6/json4s-ast_2.10-3.2.6.jar:/root/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/root/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/root/.m2/repository/colt/colt/1.2.0/colt-1.2.0.jar:/root/.m2/repository/concurrent/concurrent/1.3.4/concurrent-1.3.4.jar:/root/.m2/repository/org/apache/mesos/mesos/0.18.1/mesos-0.18.1-shaded-protobuf.jar:/root/.m2/repository/io/netty/netty-all/4.0.17.Final/netty-all-4.0.17.Final.jar:/root/.m2/repository/com/clearspring/analytics/stream/2.5.1/stream-2.5.1.jar:/root/.m2/repository/com/codahale/metrics/metrics-core/3.0.0/metrics-core-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-jvm/3.0.0/metrics-jvm-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-json/3.0.0/metrics-json-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-graphite/3.0.0/metrics-graphite-3.0.0.jar:/root/.m2/repository/org/spark-project/pyrolite/2.0.1/pyrolite-2.0.1.jar:/root/.m2/repository/net/sf/py4j/py4j/0.8.1/py4j-0.8.1.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.3.2/jackson-annotations-2.3.2.jar:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.3.0-mr1-cdh5.1.0/hadoop-client-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.3.0-cdh5.1.0/hadoop-common-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.3.0-cdh5.1.0/hadoop-annotations-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.3.0-cdh5.1.0/hadoop-auth-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/root/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.3.0-cdh5.1.0/hadoop-hdfs-2.3.0-cdh5.1.0.jar:/root/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/.m2/repository/org/apache/hadoop/hadoop-core/2.3.0-mr1-cdh5.1.0/hadoop-core-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/.m2/repository/org/springframework/spring-context/3.0.5.RELEASE/spring-context-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-aop/3.0.5.RELEASE/spring-aop-3.0.5.RELEASE.jar:/root/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/.m2/repository/org/springframework/spring-beans/3.0.5.RELEASE/spring-beans-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-core/3.0.5.RELEASE/spring-core-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-expression/3.0.5.RELEASE/spring-expression-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-asm/3.0.5.RELEASE/spring-asm-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/data/spring-data-hadoop/1.0.0.RELEASE/spring-data-hadoop-1.0.0.RELEASE.jar:/root/.m2/repository/org/apache/hadoop/hadoop-streaming/1.0.4/hadoop-streaming-1.0.4.jar:/root/.m2/repository/org/apache/hadoop/hadoop-tools/1.0.4/hadoop-tools-1.0.4.jar:/root/.m2/repository/org/springframework/spring-context-support/3.0.7.RELEASE/spring-context-support-3.0.7.RELEASE.jar:/root/.m2/repository/org/springframework/spring-jdbc/3.2.3.RELEASE/spring-jdbc-3.2.3.RELEASE.jar:/root/.m2/repository/org/springframework/spring-tx/3.2.3.RELEASE/spring-tx-3.2.3.RELEASE.jar:/root/.m2/repository/io/spray/spray-json_2.10/1.2.6/spray-json_2.10-1.2.6.jar:/root/.m2/repository/org/parboiled/parboiled-scala_2.10/1.1.6/parboiled-scala_2.10-1.1.6.jar:/root/.m2/repository/org/parboiled/parboiled-core/1.1.6/parboiled-core-1.1.6.jar:/root/.m2/repository/org/apache/spark/spark-sql_2.10/1.0.1/spark-sql_2.10-1.0.1.jar:/root/.m2/repository/org/apache/spark/spark-catalyst_2.10/1.0.1/spark-catalyst_2.10-1.0.1.jar:/root/.m2/repository/com/typesafe/scalalogging-slf4j_2.10/1.0.1/scalalogging-slf4j_2.10-1.0.1.jar:/root/.m2/repository/com/twitter/parquet-column/1.4.3/parquet-column-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-common/1.4.3/parquet-common-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-encoding/1.4.3/parquet-encoding-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-generator/1.4.3/parquet-generator-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-hadoop/1.4.3/parquet-hadoop-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-format/2.0.0/parquet-format-2.0.0.jar:/root/.m2/repository/com/twitter/parquet-jackson/1.4.3/parquet-jackson-1.4.3.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.3.0/jackson-databind-2.3.0.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.3.0/jackson-core-2.3.0.jar:/root/.m2/repository/org/apache/spark/spark-hive_2.10/1.0.1/spark-hive_2.10-1.0.1.jar:/root/.m2/repository/org/spark-project/hive/hive-metastore/0.12.0/hive-metastore-0.12.0.jar:/root/.m2/repository/org/antlr/antlr/3.4/antlr-3.4.jar:/root/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/root/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/root/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/root/.m2/repository/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar:/root/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/root/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar:/root/.m2/repository/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar:/root/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar:/root/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/root/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/root/.m2/repository/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar:/root/.m2/repository/org/spark-project/hive/hive-exec/0.12.0/hive-exec-0.12.0.jar:/root/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/root/.m2/repository/org/json/json/20090211/json-20090211.jar:/root/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/root/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/root/.m2/repository/org/spark-project/hive/hive-serde/0.12.0/hive-serde-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-common/0.12.0/hive-common-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-shims/0.12.0/hive-shims-0.12.0.jar:/root/.m2/repository/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar:/root/.m2/repository/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar:/root/.m2/repository/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar:/root/.m2/repository/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar:/root/.m2/repository/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar:/root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/root/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/root/.m2/repository/org/apache/avro/avro/1.7.6/avro-1.7.6.jar:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:java.io.tmpdir=/tmp
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:java.compiler=<NA>
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:os.name=Linux
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:os.arch=amd64
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:os.version=3.8.0-26-generic
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:user.name=root
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:user.home=/root
2014-07-21 18:13:12 main ZooKeeper [INFO] Client environment:user.dir=/home/ema/work/jawsGit/http-spark-sql-server/test-project
2014-07-21 18:13:12 main ZooKeeper [INFO] Initiating client connection, connectString=ip-10-0-2-16.ec2.internal,ip-10-0-2-18.ec2.internal,ip-10-0-2-17.ec2.internal:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@617578a3
2014-07-21 18:13:12 main ZooKeeperHiveLockManager [ERROR] Failed to create ZooKeeper object: 
java.net.UnknownHostException: ip-10-0-2-16.ec2.internal: System error
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:901)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1293)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1246)
	at java.net.InetAddress.getAllByName(InetAddress.java:1162)
	at java.net.InetAddress.getAllByName(InetAddress.java:1098)
	at org.apache.zookeeper.client.StaticHostProvider.<init>(StaticHostProvider.java:60)
	at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:445)
	at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:380)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.renewZookeeperInstance(ZooKeeperHiveLockManager.java:149)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.setContext(ZooKeeperHiveLockManager.java:117)
	at org.apache.hadoop.hive.ql.Driver.setLockManager(Driver.java:174)
	at org.apache.hadoop.hive.ql.Driver.checkLockManager(Driver.java:146)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:985)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)
2014-07-21 18:13:12 main Driver [ERROR] FAILED: Error in semantic analysis: Lock manager could not be initialized, check hive.lock.manager Check hive.zookeeper.quorum and hive.zookeeper.client.port
org.apache.hadoop.hive.ql.parse.SemanticException: Lock manager could not be initialized, check hive.lock.manager Check hive.zookeeper.quorum and hive.zookeeper.client.port
	at org.apache.hadoop.hive.ql.Driver.setLockManager(Driver.java:186)
	at org.apache.hadoop.hive.ql.Driver.checkLockManager(Driver.java:146)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:985)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)

2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=Driver.execute>
2014-07-21 18:13:12 main Driver [INFO] Starting command: show databases
2014-07-21 18:13:12 main Driver [INFO] </PERFLOG method=TimeToSubmit start=1405955592364 end=1405955592661 duration=297>
2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=runTasks>
2014-07-21 18:13:12 main Driver [INFO] <PERFLOG method=task.DDL.Stage-0>
2014-07-21 18:13:12 main metastore [INFO] Trying to connect to metastore with URI thrift://ip-10-0-2-16.ec2.internal:9083
2014-07-21 18:13:12 main metastore [WARN] Failed to connect to the MetaStore Server...
2014-07-21 18:13:12 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:13:13 main metastore [INFO] Trying to connect to metastore with URI thrift://ip-10-0-2-16.ec2.internal:9083
2014-07-21 18:13:13 main metastore [WARN] Failed to connect to the MetaStore Server...
2014-07-21 18:13:13 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:13:14 main metastore [INFO] Trying to connect to metastore with URI thrift://ip-10-0-2-16.ec2.internal:9083
2014-07-21 18:13:14 main metastore [WARN] Failed to connect to the MetaStore Server...
2014-07-21 18:13:14 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:13:15 main DDLTask [ERROR] org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1074)
	at org.apache.hadoop.hive.ql.exec.DDLTask.showDatabases(DDLTask.java:2198)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:328)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1414)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1192)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1020)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)
Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1212)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:62)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2372)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2383)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1072)
	... 29 more
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1210)
	... 34 more
Caused by: MetaException(message:Could not connect to meta store using any of the URIs provided. Most recent failure: org.apache.thrift.transport.TTransportException: java.net.UnknownHostException: ip-10-0-2-16.ec2.internal
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:283)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1210)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:62)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2372)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2383)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1072)
	at org.apache.hadoop.hive.ql.exec.DDLTask.showDatabases(DDLTask.java:2198)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:328)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1414)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1192)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1020)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)
Caused by: java.net.UnknownHostException: ip-10-0-2-16.ec2.internal
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:178)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 41 more
)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:329)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)
	... 39 more

2014-07-21 18:13:15 main Driver [INFO] </PERFLOG method=task.DDL.Stage-0 start=1405955592661 end=1405955595699 duration=3038>
2014-07-21 18:13:15 main Driver [ERROR] FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient
2014-07-21 18:13:15 main Driver [INFO] </PERFLOG method=Driver.execute start=1405955592646 end=1405955595700 duration=3054>
2014-07-21 18:13:15 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:13:15 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955595701 end=1405955595701 duration=0>
2014-07-21 18:13:15 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:13:15 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955595704 end=1405955595705 duration=1>
2014-07-21 18:13:15 main HiveContext [ERROR] 
======================
HIVE FAILURE OUTPUT
======================
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       FAILED: Error in semantic analysis: Lock manager could not be initialized, check hive.lock.manager Check hive.zookeeper.quorum and hive.zookeeper.client.port
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient

======================
END HIVE FAILURE OUTPUT
======================
          
2014-07-21 18:14:54 main JawsController$ [INFO] Initializing...
2014-07-21 18:15:00 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:15:00 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:15:05 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:15:05 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:15:05 spark-akka.actor.default-dispatcher-3 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:15:05 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Starting remoting
2014-07-21 18:15:06 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:48774]
2014-07-21 18:15:06 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:48774]
2014-07-21 18:15:06 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:15:06 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:15:06 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721181506-94e0
2014-07-21 18:15:06 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:15:06 main ConnectionManager [INFO] Bound socket to port 54356 with id = ConnectionManagerId(5.5.21.123,54356)
2014-07-21 18:15:06 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:15:06 spark-akka.actor.default-dispatcher-2 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:54356 with 1061.8 MB RAM
2014-07-21 18:15:06 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:15:06 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:15:06 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:15:06 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:47412
2014-07-21 18:15:06 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:47412
2014-07-21 18:15:06 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-ea778264-3b3d-425f-b4dd-78446edaaaf7
2014-07-21 18:15:06 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:15:06 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:15:06 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:42611
2014-07-21 18:15:11 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:15:11 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:15:11 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:15:11 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:15:12 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:42611/jars/test-app.jar with timestamp 1405955712025
2014-07-21 18:15:12 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:15:12 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-13 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721151515-0003
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-13 AppClient$ClientActor [INFO] Executor added: app-20140721151515-0003/0 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-13 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151515-0003/0 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-13 AppClient$ClientActor [INFO] Executor added: app-20140721151515-0003/1 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-13 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151515-0003/1 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-13 AppClient$ClientActor [INFO] Executor updated: app-20140721151515-0003/1 is now RUNNING
2014-07-21 18:15:12 spark-akka.actor.default-dispatcher-13 AppClient$ClientActor [INFO] Executor updated: app-20140721151515-0003/0 is now RUNNING
2014-07-21 18:15:12 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:15:12 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:15:13 main ParseDriver [INFO] Parse Completed
2014-07-21 18:15:13 main Analyzer [INFO] Max iterations (2) reached for batch MultiInstanceRelations
2014-07-21 18:15:13 main Analyzer [INFO] Max iterations (2) reached for batch CaseInsensitiveAttributeReferences
2014-07-21 18:15:13 main Analyzer [INFO] Max iterations (2) reached for batch Check Analysis
2014-07-21 18:15:13 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Add exchange
2014-07-21 18:15:13 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Prepare Expressions
2014-07-21 18:15:13 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=Driver.run>
2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=TimeToSubmit>
2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=compile>
2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=parse>
2014-07-21 18:15:13 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:15:13 main ParseDriver [INFO] Parse Completed
2014-07-21 18:15:13 main Driver [INFO] </PERFLOG method=parse start=1405955713615 end=1405955713616 duration=1>
2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=semanticAnalyze>
2014-07-21 18:15:13 main Driver [INFO] Semantic Analysis Completed
2014-07-21 18:15:13 main Driver [INFO] </PERFLOG method=semanticAnalyze start=1405955713616 end=1405955713741 duration=125>
2014-07-21 18:15:13 main ListSinkOperator [INFO] Initializing Self 0 OP
2014-07-21 18:15:13 main ListSinkOperator [INFO] Operator 0 OP initialized
2014-07-21 18:15:13 main ListSinkOperator [INFO] Initialization Done 0 OP
2014-07-21 18:15:13 main Driver [INFO] Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
2014-07-21 18:15:13 main Driver [INFO] </PERFLOG method=compile start=1405955713591 end=1405955713835 duration=244>
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:host.name=ema-Latitude-E6530
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:java.version=1.7.0_51
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:java.vendor=Oracle Corporation
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:java.home=/usr/lib/jvm/jdk1.7.0/jre
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:java.class.path=/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/classes:/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-classes:/root/.m2/repository/io/spray/spray-client/1.2.1/spray-client-1.2.1.jar:/root/.m2/repository/io/spray/spray-http/1.2.1/spray-http-1.2.1.jar:/root/.m2/repository/io/spray/spray-httpx/1.2.1/spray-httpx-1.2.1.jar:/root/.m2/repository/org/jvnet/mimepull/mimepull/1.9.4/mimepull-1.9.4.jar:/root/.m2/repository/io/spray/spray-util/1.2.1/spray-util-1.2.1.jar:/root/.m2/repository/org/scalamock/scalamock-scalatest-support_2.10/3.1.RC1/scalamock-scalatest-support_2.10-3.1.RC1.jar:/root/.m2/repository/org/scalamock/scalamock-core_2.10/3.1.RC1/scalamock-core_2.10-3.1.RC1.jar:/root/.m2/repository/org/scala-lang/scala-reflect/2.10.0/scala-reflect-2.10.0.jar:/root/.m2/repository/org/scalatest/scalatest_2.10/2.0/scalatest_2.10-2.0.jar:/root/.m2/repository/junit/junit/4.4/junit-4.4.jar:/root/.m2/repository/io/spray/spray-routing/1.2.1/spray-routing-1.2.1.jar:/root/.m2/repository/com/chuusai/shapeless_2.10/1.2.4/shapeless_2.10-1.2.4.jar:/root/.m2/repository/io/spray/spray-can/1.2.1/spray-can-1.2.1.jar:/root/.m2/repository/io/spray/spray-io/1.2.1/spray-io-1.2.1.jar:/root/.m2/repository/io/spray/spray-caching/1.2.1/spray-caching-1.2.1.jar:/root/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.3/jsr305-2.0.3.jar:/root/.m2/repository/org/tachyonproject/tachyon/0.4.1-thrift/tachyon-0.4.1-thrift.jar:/root/.m2/repository/org/apache/ant/ant/1.9.0/ant-1.9.0.jar:/root/.m2/repository/org/apache/ant/ant-launcher/1.9.0/ant-launcher-1.9.0.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jsp/7.6.8.v20121106/jetty-jsp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp/2.1.0.v201105211820/javax.servlet.jsp-2.1.0.v201105211820.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.jasper.glassfish/2.1.0.v201110031002/org.apache.jasper.glassfish-2.1.0.v201110031002.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp.jstl/1.2.0.v201105211821/javax.servlet.jsp.jstl-1.2.0.v201105211821.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.taglibs.standard.glassfish/1.2.0.v201112081803/org.apache.taglibs.standard.glassfish-1.2.0.v201112081803.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.el/2.1.0.v201105211819/javax.el-2.1.0.v201105211819.jar:/root/.m2/repository/org/eclipse/jetty/orbit/com.sun.el/1.0.0.v201105211818/com.sun.el-1.0.0.v201105211818.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.eclipse.jdt.core/3.7.1/org.eclipse.jdt.core-3.7.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-webapp/7.6.8.v20121106/jetty-webapp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-xml/7.6.8.v20121106/jetty-xml-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-servlet/7.6.8.v20121106/jetty-servlet-7.6.8.v20121106.jar:/root/.m2/repository/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.2/slf4j-log4j12-1.7.2.jar:/root/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/.m2/repository/org/apache/commons/commons-lang3/3.0/commons-lang3-3.0.jar:/root/.m2/repository/org/apache/curator/curator-recipes/2.1.0-incubating/curator-recipes-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-framework/2.1.0-incubating/curator-framework-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-client/2.1.0-incubating/curator-client-2.1.0-incubating.jar:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/root/.m2/repository/org/java-websocket/Java-WebSocket/1.3.0/Java-WebSocket-1.3.0.jar:/root/.m2/repository/org/apache/spark/spark-core_2.10/1.0.1/spark-core_2.10-1.0.1.jar:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/root/.m2/repository/commons-codec/commons-codec/1.3/commons-codec-1.3.jar:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-plus/8.1.14.v20131031/jetty-plus-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.transaction/1.1.1.v201105210645/javax.transaction-1.1.1.v201105210645.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jndi/8.1.14.v20131031/jetty-jndi-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.mail.glassfish/1.4.1.v201005082020/javax.mail.glassfish-1.4.1.v201005082020.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.activation/1.1.0.v201105071233/javax.activation-1.1.0.v201105071233.jar:/root/.m2/repository/org/eclipse/jetty/jetty-security/8.1.14.v20131031/jetty-security-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/root/.m2/repository/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar:/root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/root/.m2/repository/org/slf4j/jul-to-slf4j/1.7.5/jul-to-slf4j-1.7.5.jar:/root/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.5/jcl-over-slf4j-1.7.5.jar:/root/.m2/repository/com/ning/compress-lzf/1.0.0/compress-lzf-1.0.0.jar:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/root/.m2/repository/com/twitter/chill_2.10/0.3.6/chill_2.10-0.3.6.jar:/root/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/.m2/repository/com/twitter/chill-java/0.3.6/chill-java-0.3.6.jar:/root/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/root/.m2/repository/org/spark-project/akka/akka-remote_2.10/2.2.3-shaded-protobuf/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/spark-project/akka/akka-actor_2.10/2.2.3-shaded-protobuf/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/com/typesafe/config/1.0.2/config-1.0.2.jar:/root/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar:/root/.m2/repository/org/spark-project/protobuf/protobuf-java/2.4.1-shaded/protobuf-java-2.4.1-shaded.jar:/root/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/root/.m2/repository/org/spark-project/akka/akka-slf4j_2.10/2.2.3-shaded-protobuf/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.6/json4s-jackson_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-core_2.10/3.2.6/json4s-core_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-ast_2.10/3.2.6/json4s-ast_2.10-3.2.6.jar:/root/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/root/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/root/.m2/repository/colt/colt/1.2.0/colt-1.2.0.jar:/root/.m2/repository/concurrent/concurrent/1.3.4/concurrent-1.3.4.jar:/root/.m2/repository/org/apache/mesos/mesos/0.18.1/mesos-0.18.1-shaded-protobuf.jar:/root/.m2/repository/io/netty/netty-all/4.0.17.Final/netty-all-4.0.17.Final.jar:/root/.m2/repository/com/clearspring/analytics/stream/2.5.1/stream-2.5.1.jar:/root/.m2/repository/com/codahale/metrics/metrics-core/3.0.0/metrics-core-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-jvm/3.0.0/metrics-jvm-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-json/3.0.0/metrics-json-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-graphite/3.0.0/metrics-graphite-3.0.0.jar:/root/.m2/repository/org/spark-project/pyrolite/2.0.1/pyrolite-2.0.1.jar:/root/.m2/repository/net/sf/py4j/py4j/0.8.1/py4j-0.8.1.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.3.2/jackson-annotations-2.3.2.jar:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.3.0-mr1-cdh5.1.0/hadoop-client-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.3.0-cdh5.1.0/hadoop-common-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.3.0-cdh5.1.0/hadoop-annotations-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.3.0-cdh5.1.0/hadoop-auth-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/root/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.3.0-cdh5.1.0/hadoop-hdfs-2.3.0-cdh5.1.0.jar:/root/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/.m2/repository/org/apache/hadoop/hadoop-core/2.3.0-mr1-cdh5.1.0/hadoop-core-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/.m2/repository/org/springframework/spring-context/3.0.5.RELEASE/spring-context-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-aop/3.0.5.RELEASE/spring-aop-3.0.5.RELEASE.jar:/root/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/.m2/repository/org/springframework/spring-beans/3.0.5.RELEASE/spring-beans-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-core/3.0.5.RELEASE/spring-core-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-expression/3.0.5.RELEASE/spring-expression-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-asm/3.0.5.RELEASE/spring-asm-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/data/spring-data-hadoop/1.0.0.RELEASE/spring-data-hadoop-1.0.0.RELEASE.jar:/root/.m2/repository/org/apache/hadoop/hadoop-streaming/1.0.4/hadoop-streaming-1.0.4.jar:/root/.m2/repository/org/apache/hadoop/hadoop-tools/1.0.4/hadoop-tools-1.0.4.jar:/root/.m2/repository/org/springframework/spring-context-support/3.0.7.RELEASE/spring-context-support-3.0.7.RELEASE.jar:/root/.m2/repository/org/springframework/spring-jdbc/3.2.3.RELEASE/spring-jdbc-3.2.3.RELEASE.jar:/root/.m2/repository/org/springframework/spring-tx/3.2.3.RELEASE/spring-tx-3.2.3.RELEASE.jar:/root/.m2/repository/io/spray/spray-json_2.10/1.2.6/spray-json_2.10-1.2.6.jar:/root/.m2/repository/org/parboiled/parboiled-scala_2.10/1.1.6/parboiled-scala_2.10-1.1.6.jar:/root/.m2/repository/org/parboiled/parboiled-core/1.1.6/parboiled-core-1.1.6.jar:/root/.m2/repository/org/apache/spark/spark-sql_2.10/1.0.1/spark-sql_2.10-1.0.1.jar:/root/.m2/repository/org/apache/spark/spark-catalyst_2.10/1.0.1/spark-catalyst_2.10-1.0.1.jar:/root/.m2/repository/com/typesafe/scalalogging-slf4j_2.10/1.0.1/scalalogging-slf4j_2.10-1.0.1.jar:/root/.m2/repository/com/twitter/parquet-column/1.4.3/parquet-column-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-common/1.4.3/parquet-common-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-encoding/1.4.3/parquet-encoding-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-generator/1.4.3/parquet-generator-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-hadoop/1.4.3/parquet-hadoop-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-format/2.0.0/parquet-format-2.0.0.jar:/root/.m2/repository/com/twitter/parquet-jackson/1.4.3/parquet-jackson-1.4.3.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.3.0/jackson-databind-2.3.0.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.3.0/jackson-core-2.3.0.jar:/root/.m2/repository/org/apache/spark/spark-hive_2.10/1.0.1/spark-hive_2.10-1.0.1.jar:/root/.m2/repository/org/spark-project/hive/hive-metastore/0.12.0/hive-metastore-0.12.0.jar:/root/.m2/repository/org/antlr/antlr/3.4/antlr-3.4.jar:/root/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/root/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/root/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/root/.m2/repository/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar:/root/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/root/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar:/root/.m2/repository/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar:/root/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar:/root/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/root/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/root/.m2/repository/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar:/root/.m2/repository/org/spark-project/hive/hive-exec/0.12.0/hive-exec-0.12.0.jar:/root/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/root/.m2/repository/org/json/json/20090211/json-20090211.jar:/root/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/root/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/root/.m2/repository/org/spark-project/hive/hive-serde/0.12.0/hive-serde-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-common/0.12.0/hive-common-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-shims/0.12.0/hive-shims-0.12.0.jar:/root/.m2/repository/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar:/root/.m2/repository/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar:/root/.m2/repository/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar:/root/.m2/repository/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar:/root/.m2/repository/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar:/root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/root/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/root/.m2/repository/org/apache/avro/avro/1.7.6/avro-1.7.6.jar:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:java.io.tmpdir=/tmp
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:java.compiler=<NA>
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:os.name=Linux
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:os.arch=amd64
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:os.version=3.8.0-26-generic
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:user.name=root
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:user.home=/root
2014-07-21 18:15:13 main ZooKeeper [INFO] Client environment:user.dir=/home/ema/work/jawsGit/http-spark-sql-server/test-project
2014-07-21 18:15:13 main ZooKeeper [INFO] Initiating client connection, connectString=ip-10-0-2-16.ec2.internal,ip-10-0-2-18.ec2.internal,ip-10-0-2-17.ec2.internal:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@703546fc
2014-07-21 18:15:13 main ZooKeeperHiveLockManager [ERROR] Failed to create ZooKeeper object: 
java.net.UnknownHostException: ip-10-0-2-16.ec2.internal: System error
	at java.net.Inet6AddressImpl.lookupAllHostAddr(Native Method)
	at java.net.InetAddress$1.lookupAllHostAddr(InetAddress.java:901)
	at java.net.InetAddress.getAddressesFromNameService(InetAddress.java:1293)
	at java.net.InetAddress.getAllByName0(InetAddress.java:1246)
	at java.net.InetAddress.getAllByName(InetAddress.java:1162)
	at java.net.InetAddress.getAllByName(InetAddress.java:1098)
	at org.apache.zookeeper.client.StaticHostProvider.<init>(StaticHostProvider.java:60)
	at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:445)
	at org.apache.zookeeper.ZooKeeper.<init>(ZooKeeper.java:380)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.renewZookeeperInstance(ZooKeeperHiveLockManager.java:149)
	at org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager.setContext(ZooKeeperHiveLockManager.java:117)
	at org.apache.hadoop.hive.ql.Driver.setLockManager(Driver.java:174)
	at org.apache.hadoop.hive.ql.Driver.checkLockManager(Driver.java:146)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:985)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)
2014-07-21 18:15:13 main Driver [ERROR] FAILED: Error in semantic analysis: Lock manager could not be initialized, check hive.lock.manager Check hive.zookeeper.quorum and hive.zookeeper.client.port
org.apache.hadoop.hive.ql.parse.SemanticException: Lock manager could not be initialized, check hive.lock.manager Check hive.zookeeper.quorum and hive.zookeeper.client.port
	at org.apache.hadoop.hive.ql.Driver.setLockManager(Driver.java:186)
	at org.apache.hadoop.hive.ql.Driver.checkLockManager(Driver.java:146)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:985)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)

2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=Driver.execute>
2014-07-21 18:15:13 main Driver [INFO] Starting command: show databases
2014-07-21 18:15:13 main Driver [INFO] </PERFLOG method=TimeToSubmit start=1405955713591 end=1405955713876 duration=285>
2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=runTasks>
2014-07-21 18:15:13 main Driver [INFO] <PERFLOG method=task.DDL.Stage-0>
2014-07-21 18:15:13 main metastore [INFO] Trying to connect to metastore with URI thrift://ip-10-0-2-16.ec2.internal:9083
2014-07-21 18:15:13 main metastore [WARN] Failed to connect to the MetaStore Server...
2014-07-21 18:15:13 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:15:14 main metastore [INFO] Trying to connect to metastore with URI thrift://ip-10-0-2-16.ec2.internal:9083
2014-07-21 18:15:14 main metastore [WARN] Failed to connect to the MetaStore Server...
2014-07-21 18:15:14 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:15:15 main metastore [INFO] Trying to connect to metastore with URI thrift://ip-10-0-2-16.ec2.internal:9083
2014-07-21 18:15:15 main metastore [WARN] Failed to connect to the MetaStore Server...
2014-07-21 18:15:15 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:15:16 main DDLTask [ERROR] org.apache.hadoop.hive.ql.metadata.HiveException: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1074)
	at org.apache.hadoop.hive.ql.exec.DDLTask.showDatabases(DDLTask.java:2198)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:328)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1414)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1192)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1020)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)
Caused by: java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1212)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:62)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2372)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2383)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1072)
	... 29 more
Caused by: java.lang.reflect.InvocationTargetException
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1210)
	... 34 more
Caused by: MetaException(message:Could not connect to meta store using any of the URIs provided. Most recent failure: org.apache.thrift.transport.TTransportException: java.net.UnknownHostException: ip-10-0-2-16.ec2.internal
	at org.apache.thrift.transport.TSocket.open(TSocket.java:185)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:283)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)
	at sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:57)
	at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
	at java.lang.reflect.Constructor.newInstance(Constructor.java:526)
	at org.apache.hadoop.hive.metastore.MetaStoreUtils.newInstance(MetaStoreUtils.java:1210)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.<init>(RetryingMetaStoreClient.java:62)
	at org.apache.hadoop.hive.metastore.RetryingMetaStoreClient.getProxy(RetryingMetaStoreClient.java:72)
	at org.apache.hadoop.hive.ql.metadata.Hive.createMetaStoreClient(Hive.java:2372)
	at org.apache.hadoop.hive.ql.metadata.Hive.getMSC(Hive.java:2383)
	at org.apache.hadoop.hive.ql.metadata.Hive.getAllDatabases(Hive.java:1072)
	at org.apache.hadoop.hive.ql.exec.DDLTask.showDatabases(DDLTask.java:2198)
	at org.apache.hadoop.hive.ql.exec.DDLTask.execute(DDLTask.java:328)
	at org.apache.hadoop.hive.ql.exec.Task.executeTask(Task.java:151)
	at org.apache.hadoop.hive.ql.exec.TaskRunner.runSequential(TaskRunner.java:65)
	at org.apache.hadoop.hive.ql.Driver.launchTask(Driver.java:1414)
	at org.apache.hadoop.hive.ql.Driver.execute(Driver.java:1192)
	at org.apache.hadoop.hive.ql.Driver.runInternal(Driver.java:1020)
	at org.apache.hadoop.hive.ql.Driver.run(Driver.java:888)
	at org.apache.spark.sql.hive.HiveContext.runHive(HiveContext.scala:189)
	at org.apache.spark.sql.hive.HiveContext.runSqlHive(HiveContext.scala:163)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult$lzycompute(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.sideEffectResult(NativeCommand.scala:35)
	at org.apache.spark.sql.hive.execution.NativeCommand.execute(NativeCommand.scala:38)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd$lzycompute(HiveContext.scala:250)
	at org.apache.spark.sql.hive.HiveContext$QueryExecution.toRdd(HiveContext.scala:250)
	at org.apache.spark.sql.SchemaRDDLike$class.$init$(SchemaRDDLike.scala:58)
	at org.apache.spark.sql.SchemaRDD.<init>(SchemaRDD.scala:100)
	at org.apache.spark.sql.hive.HiveContext.hiveql(HiveContext.scala:75)
	at org.apache.spark.sql.hive.HiveContext.hql(HiveContext.scala:78)
	at actors.JawsController$delayedInit$body.apply(JawsController.scala:81)
	at scala.Function0$class.apply$mcV$sp(Function0.scala:40)
	at scala.runtime.AbstractFunction0.apply$mcV$sp(AbstractFunction0.scala:12)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.App$$anonfun$main$1.apply(App.scala:71)
	at scala.collection.immutable.List.foreach(List.scala:318)
	at scala.collection.generic.TraversableForwarder$class.foreach(TraversableForwarder.scala:32)
	at scala.App$class.main(App.scala:71)
	at actors.JawsController$.main(JawsController.scala:28)
	at actors.JawsController.main(JawsController.scala)
Caused by: java.net.UnknownHostException: ip-10-0-2-16.ec2.internal
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:178)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:579)
	at org.apache.thrift.transport.TSocket.open(TSocket.java:180)
	... 41 more
)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.open(HiveMetaStoreClient.java:329)
	at org.apache.hadoop.hive.metastore.HiveMetaStoreClient.<init>(HiveMetaStoreClient.java:164)
	... 39 more

2014-07-21 18:15:16 main Driver [INFO] </PERFLOG method=task.DDL.Stage-0 start=1405955713877 end=1405955716919 duration=3042>
2014-07-21 18:15:16 main Driver [ERROR] FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient
2014-07-21 18:15:16 main Driver [INFO] </PERFLOG method=Driver.execute start=1405955713865 end=1405955716921 duration=3056>
2014-07-21 18:15:16 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:15:16 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955716921 end=1405955716921 duration=0>
2014-07-21 18:15:16 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:15:16 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955716924 end=1405955716925 duration=1>
2014-07-21 18:15:16 main HiveContext [ERROR] 
======================
HIVE FAILURE OUTPUT
======================
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       FAILED: Error in semantic analysis: Lock manager could not be initialized, check hive.lock.manager Check hive.zookeeper.quorum and hive.zookeeper.client.port
FAILED: Execution Error, return code 1 from org.apache.hadoop.hive.ql.exec.DDLTask. java.lang.RuntimeException: Unable to instantiate org.apache.hadoop.hive.metastore.HiveMetaStoreClient

======================
END HIVE FAILURE OUTPUT
======================
          
2014-07-21 18:15:30 main JawsController$ [INFO] Initializing...
2014-07-21 18:15:36 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:15:36 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:15:41 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:15:41 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:15:41 spark-akka.actor.default-dispatcher-4 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:15:41 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Starting remoting
2014-07-21 18:15:41 spark-akka.actor.default-dispatcher-2 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:42096]
2014-07-21 18:15:41 spark-akka.actor.default-dispatcher-2 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:42096]
2014-07-21 18:15:41 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:15:41 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:15:41 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721181541-23c4
2014-07-21 18:15:41 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:15:41 main ConnectionManager [INFO] Bound socket to port 48593 with id = ConnectionManagerId(5.5.21.123,48593)
2014-07-21 18:15:41 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:15:41 spark-akka.actor.default-dispatcher-4 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:48593 with 1061.8 MB RAM
2014-07-21 18:15:41 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:15:41 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:15:41 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:15:41 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:40988
2014-07-21 18:15:41 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:40988
2014-07-21 18:15:41 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-0df917ba-4af6-4edc-a86a-1318ac62329a
2014-07-21 18:15:41 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:15:41 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:15:41 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:52698
2014-07-21 18:15:47 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:15:47 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:15:47 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:15:47 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:15:47 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:52698/jars/test-app.jar with timestamp 1405955747449
2014-07-21 18:15:47 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:15:47 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:15:48 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:15:48 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721151550-0004
2014-07-21 18:15:48 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor added: app-20140721151550-0004/0 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:15:48 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151550-0004/0 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:15:48 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor added: app-20140721151550-0004/1 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:15:48 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151550-0004/1 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:15:48 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721151550-0004/1 is now RUNNING
2014-07-21 18:15:48 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor updated: app-20140721151550-0004/0 is now RUNNING
2014-07-21 18:15:48 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:15:48 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:15:48 main ParseDriver [INFO] Parse Completed
2014-07-21 18:15:48 main Analyzer [INFO] Max iterations (2) reached for batch MultiInstanceRelations
2014-07-21 18:15:48 main Analyzer [INFO] Max iterations (2) reached for batch CaseInsensitiveAttributeReferences
2014-07-21 18:15:48 main Analyzer [INFO] Max iterations (2) reached for batch Check Analysis
2014-07-21 18:15:48 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Add exchange
2014-07-21 18:15:48 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Prepare Expressions
2014-07-21 18:15:48 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:15:48 main Driver [INFO] <PERFLOG method=Driver.run>
2014-07-21 18:15:48 main Driver [INFO] <PERFLOG method=TimeToSubmit>
2014-07-21 18:15:48 main Driver [INFO] <PERFLOG method=compile>
2014-07-21 18:15:48 main Driver [INFO] <PERFLOG method=parse>
2014-07-21 18:15:48 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:15:48 main ParseDriver [INFO] Parse Completed
2014-07-21 18:15:48 main Driver [INFO] </PERFLOG method=parse start=1405955748992 end=1405955748993 duration=1>
2014-07-21 18:15:48 main Driver [INFO] <PERFLOG method=semanticAnalyze>
2014-07-21 18:15:49 main Driver [INFO] Semantic Analysis Completed
2014-07-21 18:15:49 main Driver [INFO] </PERFLOG method=semanticAnalyze start=1405955748993 end=1405955749114 duration=121>
2014-07-21 18:15:49 main ListSinkOperator [INFO] Initializing Self 0 OP
2014-07-21 18:15:49 main ListSinkOperator [INFO] Operator 0 OP initialized
2014-07-21 18:15:49 main ListSinkOperator [INFO] Initialization Done 0 OP
2014-07-21 18:15:49 main Driver [INFO] Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
2014-07-21 18:15:49 main Driver [INFO] </PERFLOG method=compile start=1405955748968 end=1405955749178 duration=210>
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:host.name=ema-Latitude-E6530
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:java.version=1.7.0_51
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:java.vendor=Oracle Corporation
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:java.home=/usr/lib/jvm/jdk1.7.0/jre
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:java.class.path=/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/classes:/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-classes:/root/.m2/repository/io/spray/spray-client/1.2.1/spray-client-1.2.1.jar:/root/.m2/repository/io/spray/spray-http/1.2.1/spray-http-1.2.1.jar:/root/.m2/repository/io/spray/spray-httpx/1.2.1/spray-httpx-1.2.1.jar:/root/.m2/repository/org/jvnet/mimepull/mimepull/1.9.4/mimepull-1.9.4.jar:/root/.m2/repository/io/spray/spray-util/1.2.1/spray-util-1.2.1.jar:/root/.m2/repository/org/scalamock/scalamock-scalatest-support_2.10/3.1.RC1/scalamock-scalatest-support_2.10-3.1.RC1.jar:/root/.m2/repository/org/scalamock/scalamock-core_2.10/3.1.RC1/scalamock-core_2.10-3.1.RC1.jar:/root/.m2/repository/org/scala-lang/scala-reflect/2.10.0/scala-reflect-2.10.0.jar:/root/.m2/repository/org/scalatest/scalatest_2.10/2.0/scalatest_2.10-2.0.jar:/root/.m2/repository/junit/junit/4.4/junit-4.4.jar:/root/.m2/repository/io/spray/spray-routing/1.2.1/spray-routing-1.2.1.jar:/root/.m2/repository/com/chuusai/shapeless_2.10/1.2.4/shapeless_2.10-1.2.4.jar:/root/.m2/repository/io/spray/spray-can/1.2.1/spray-can-1.2.1.jar:/root/.m2/repository/io/spray/spray-io/1.2.1/spray-io-1.2.1.jar:/root/.m2/repository/io/spray/spray-caching/1.2.1/spray-caching-1.2.1.jar:/root/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.3/jsr305-2.0.3.jar:/root/.m2/repository/org/tachyonproject/tachyon/0.4.1-thrift/tachyon-0.4.1-thrift.jar:/root/.m2/repository/org/apache/ant/ant/1.9.0/ant-1.9.0.jar:/root/.m2/repository/org/apache/ant/ant-launcher/1.9.0/ant-launcher-1.9.0.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jsp/7.6.8.v20121106/jetty-jsp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp/2.1.0.v201105211820/javax.servlet.jsp-2.1.0.v201105211820.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.jasper.glassfish/2.1.0.v201110031002/org.apache.jasper.glassfish-2.1.0.v201110031002.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp.jstl/1.2.0.v201105211821/javax.servlet.jsp.jstl-1.2.0.v201105211821.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.taglibs.standard.glassfish/1.2.0.v201112081803/org.apache.taglibs.standard.glassfish-1.2.0.v201112081803.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.el/2.1.0.v201105211819/javax.el-2.1.0.v201105211819.jar:/root/.m2/repository/org/eclipse/jetty/orbit/com.sun.el/1.0.0.v201105211818/com.sun.el-1.0.0.v201105211818.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.eclipse.jdt.core/3.7.1/org.eclipse.jdt.core-3.7.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-webapp/7.6.8.v20121106/jetty-webapp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-xml/7.6.8.v20121106/jetty-xml-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-servlet/7.6.8.v20121106/jetty-servlet-7.6.8.v20121106.jar:/root/.m2/repository/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.2/slf4j-log4j12-1.7.2.jar:/root/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/.m2/repository/org/apache/commons/commons-lang3/3.0/commons-lang3-3.0.jar:/root/.m2/repository/org/apache/curator/curator-recipes/2.1.0-incubating/curator-recipes-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-framework/2.1.0-incubating/curator-framework-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-client/2.1.0-incubating/curator-client-2.1.0-incubating.jar:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/root/.m2/repository/org/java-websocket/Java-WebSocket/1.3.0/Java-WebSocket-1.3.0.jar:/root/.m2/repository/org/apache/spark/spark-core_2.10/1.0.1/spark-core_2.10-1.0.1.jar:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/root/.m2/repository/commons-codec/commons-codec/1.3/commons-codec-1.3.jar:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-plus/8.1.14.v20131031/jetty-plus-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.transaction/1.1.1.v201105210645/javax.transaction-1.1.1.v201105210645.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jndi/8.1.14.v20131031/jetty-jndi-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.mail.glassfish/1.4.1.v201005082020/javax.mail.glassfish-1.4.1.v201005082020.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.activation/1.1.0.v201105071233/javax.activation-1.1.0.v201105071233.jar:/root/.m2/repository/org/eclipse/jetty/jetty-security/8.1.14.v20131031/jetty-security-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/root/.m2/repository/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar:/root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/root/.m2/repository/org/slf4j/jul-to-slf4j/1.7.5/jul-to-slf4j-1.7.5.jar:/root/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.5/jcl-over-slf4j-1.7.5.jar:/root/.m2/repository/com/ning/compress-lzf/1.0.0/compress-lzf-1.0.0.jar:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/root/.m2/repository/com/twitter/chill_2.10/0.3.6/chill_2.10-0.3.6.jar:/root/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/.m2/repository/com/twitter/chill-java/0.3.6/chill-java-0.3.6.jar:/root/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/root/.m2/repository/org/spark-project/akka/akka-remote_2.10/2.2.3-shaded-protobuf/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/spark-project/akka/akka-actor_2.10/2.2.3-shaded-protobuf/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/com/typesafe/config/1.0.2/config-1.0.2.jar:/root/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar:/root/.m2/repository/org/spark-project/protobuf/protobuf-java/2.4.1-shaded/protobuf-java-2.4.1-shaded.jar:/root/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/root/.m2/repository/org/spark-project/akka/akka-slf4j_2.10/2.2.3-shaded-protobuf/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.6/json4s-jackson_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-core_2.10/3.2.6/json4s-core_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-ast_2.10/3.2.6/json4s-ast_2.10-3.2.6.jar:/root/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/root/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/root/.m2/repository/colt/colt/1.2.0/colt-1.2.0.jar:/root/.m2/repository/concurrent/concurrent/1.3.4/concurrent-1.3.4.jar:/root/.m2/repository/org/apache/mesos/mesos/0.18.1/mesos-0.18.1-shaded-protobuf.jar:/root/.m2/repository/io/netty/netty-all/4.0.17.Final/netty-all-4.0.17.Final.jar:/root/.m2/repository/com/clearspring/analytics/stream/2.5.1/stream-2.5.1.jar:/root/.m2/repository/com/codahale/metrics/metrics-core/3.0.0/metrics-core-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-jvm/3.0.0/metrics-jvm-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-json/3.0.0/metrics-json-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-graphite/3.0.0/metrics-graphite-3.0.0.jar:/root/.m2/repository/org/spark-project/pyrolite/2.0.1/pyrolite-2.0.1.jar:/root/.m2/repository/net/sf/py4j/py4j/0.8.1/py4j-0.8.1.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.3.2/jackson-annotations-2.3.2.jar:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.3.0-mr1-cdh5.1.0/hadoop-client-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.3.0-cdh5.1.0/hadoop-common-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.3.0-cdh5.1.0/hadoop-annotations-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.3.0-cdh5.1.0/hadoop-auth-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/root/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.3.0-cdh5.1.0/hadoop-hdfs-2.3.0-cdh5.1.0.jar:/root/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/.m2/repository/org/apache/hadoop/hadoop-core/2.3.0-mr1-cdh5.1.0/hadoop-core-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/.m2/repository/org/springframework/spring-context/3.0.5.RELEASE/spring-context-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-aop/3.0.5.RELEASE/spring-aop-3.0.5.RELEASE.jar:/root/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/.m2/repository/org/springframework/spring-beans/3.0.5.RELEASE/spring-beans-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-core/3.0.5.RELEASE/spring-core-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-expression/3.0.5.RELEASE/spring-expression-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-asm/3.0.5.RELEASE/spring-asm-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/data/spring-data-hadoop/1.0.0.RELEASE/spring-data-hadoop-1.0.0.RELEASE.jar:/root/.m2/repository/org/apache/hadoop/hadoop-streaming/1.0.4/hadoop-streaming-1.0.4.jar:/root/.m2/repository/org/apache/hadoop/hadoop-tools/1.0.4/hadoop-tools-1.0.4.jar:/root/.m2/repository/org/springframework/spring-context-support/3.0.7.RELEASE/spring-context-support-3.0.7.RELEASE.jar:/root/.m2/repository/org/springframework/spring-jdbc/3.2.3.RELEASE/spring-jdbc-3.2.3.RELEASE.jar:/root/.m2/repository/org/springframework/spring-tx/3.2.3.RELEASE/spring-tx-3.2.3.RELEASE.jar:/root/.m2/repository/io/spray/spray-json_2.10/1.2.6/spray-json_2.10-1.2.6.jar:/root/.m2/repository/org/parboiled/parboiled-scala_2.10/1.1.6/parboiled-scala_2.10-1.1.6.jar:/root/.m2/repository/org/parboiled/parboiled-core/1.1.6/parboiled-core-1.1.6.jar:/root/.m2/repository/org/apache/spark/spark-sql_2.10/1.0.1/spark-sql_2.10-1.0.1.jar:/root/.m2/repository/org/apache/spark/spark-catalyst_2.10/1.0.1/spark-catalyst_2.10-1.0.1.jar:/root/.m2/repository/com/typesafe/scalalogging-slf4j_2.10/1.0.1/scalalogging-slf4j_2.10-1.0.1.jar:/root/.m2/repository/com/twitter/parquet-column/1.4.3/parquet-column-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-common/1.4.3/parquet-common-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-encoding/1.4.3/parquet-encoding-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-generator/1.4.3/parquet-generator-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-hadoop/1.4.3/parquet-hadoop-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-format/2.0.0/parquet-format-2.0.0.jar:/root/.m2/repository/com/twitter/parquet-jackson/1.4.3/parquet-jackson-1.4.3.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.3.0/jackson-databind-2.3.0.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.3.0/jackson-core-2.3.0.jar:/root/.m2/repository/org/apache/spark/spark-hive_2.10/1.0.1/spark-hive_2.10-1.0.1.jar:/root/.m2/repository/org/spark-project/hive/hive-metastore/0.12.0/hive-metastore-0.12.0.jar:/root/.m2/repository/org/antlr/antlr/3.4/antlr-3.4.jar:/root/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/root/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/root/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/root/.m2/repository/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar:/root/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/root/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar:/root/.m2/repository/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar:/root/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar:/root/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/root/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/root/.m2/repository/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar:/root/.m2/repository/org/spark-project/hive/hive-exec/0.12.0/hive-exec-0.12.0.jar:/root/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/root/.m2/repository/org/json/json/20090211/json-20090211.jar:/root/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/root/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/root/.m2/repository/org/spark-project/hive/hive-serde/0.12.0/hive-serde-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-common/0.12.0/hive-common-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-shims/0.12.0/hive-shims-0.12.0.jar:/root/.m2/repository/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar:/root/.m2/repository/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar:/root/.m2/repository/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar:/root/.m2/repository/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar:/root/.m2/repository/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar:/root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/root/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/root/.m2/repository/org/apache/avro/avro/1.7.6/avro-1.7.6.jar:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:java.io.tmpdir=/tmp
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:java.compiler=<NA>
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:os.name=Linux
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:os.arch=amd64
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:os.version=3.8.0-26-generic
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:user.name=root
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:user.home=/root
2014-07-21 18:15:49 main ZooKeeper [INFO] Client environment:user.dir=/home/ema/work/jawsGit/http-spark-sql-server/test-project
2014-07-21 18:15:49 main ZooKeeper [INFO] Initiating client connection, connectString=10.0.2.16,10.0.2.18,10.0.2.17:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@e030a8e
2014-07-21 18:15:49 main-SendThread(ip-10-0-2-16:2181) ClientCnxn [INFO] Opening socket connection to server ip-10-0-2-16/10.0.2.16:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-21 18:15:49 main-SendThread(ip-10-0-2-16:2181) ClientCnxn [INFO] Socket connection established to ip-10-0-2-16/10.0.2.16:2181, initiating session
2014-07-21 18:15:49 main-SendThread(ip-10-0-2-16:2181) ClientCnxn [INFO] Session establishment complete on server ip-10-0-2-16/10.0.2.16:2181, sessionid = 0x14758d1af2a00fe, negotiated timeout = 40000
2014-07-21 18:15:49 main Driver [INFO] <PERFLOG method=acquireReadWriteLocks>
2014-07-21 18:15:49 main Driver [INFO] </PERFLOG method=acquireReadWriteLocks start=1405955749493 end=1405955749493 duration=0>
2014-07-21 18:15:49 main Driver [INFO] <PERFLOG method=Driver.execute>
2014-07-21 18:15:49 main Driver [INFO] Starting command: show databases
2014-07-21 18:15:49 main Driver [INFO] </PERFLOG method=TimeToSubmit start=1405955748967 end=1405955749512 duration=545>
2014-07-21 18:15:49 main Driver [INFO] <PERFLOG method=runTasks>
2014-07-21 18:15:49 main Driver [INFO] <PERFLOG method=task.DDL.Stage-0>
2014-07-21 18:15:49 main metastore [INFO] Trying to connect to metastore with URI thrift://10.0.2.16:9083
2014-07-21 18:15:49 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:15:50 main metastore [INFO] Connected to metastore.
2014-07-21 18:15:51 main DDLTask [INFO] results : 1
2014-07-21 18:15:51 main Driver [INFO] </PERFLOG method=task.DDL.Stage-0 start=1405955749513 end=1405955751057 duration=1544>
2014-07-21 18:15:51 main Driver [INFO] </PERFLOG method=runTasks start=1405955749512 end=1405955751057 duration=1545>
2014-07-21 18:15:51 main Driver [INFO] </PERFLOG method=Driver.execute start=1405955749493 end=1405955751058 duration=1565>
2014-07-21 18:15:51 main Driver [INFO] OK
2014-07-21 18:15:51 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:15:51 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955751060 end=1405955751060 duration=0>
2014-07-21 18:15:51 main Driver [INFO] </PERFLOG method=Driver.run start=1405955748967 end=1405955751060 duration=2093>
2014-07-21 18:15:51 main FileInputFormat [INFO] Total input paths to process : 1
2014-07-21 18:15:51 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:15:51 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955751094 end=1405955751094 duration=0>
2014-07-21 18:15:51 main ZooKeeper [INFO] Session: 0x14758d1af2a00fe closed
2014-07-21 18:15:51 main-EventThread ClientCnxn [INFO] EventThread shut down
2014-07-21 18:16:19 main SparkContext [INFO] Starting job: foreach at JawsController.scala:82
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 DAGScheduler [INFO] Got job 0 (foreach at JawsController.scala:82) with 1 output partitions (allowLocal=false)
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 DAGScheduler [INFO] Final stage: Stage 0(foreach at JawsController.scala:82)
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 DAGScheduler [INFO] Parents of final stage: List()
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 DAGScheduler [INFO] Missing parents: List()
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 DAGScheduler [INFO] Submitting Stage 0 (SchemaRDD[0] at RDD at SchemaRDD.scala:100
== Query Plan ==
<Native command: executed by Hive>), which has no missing parents
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 DAGScheduler [INFO] Submitting 1 missing tasks from Stage 0 (SchemaRDD[0] at RDD at SchemaRDD.scala:100
== Query Plan ==
<Native command: executed by Hive>)
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 TaskSchedulerImpl [INFO] Adding task set 0.0 with 1 tasks
2014-07-21 18:16:19 spark-akka.actor.default-dispatcher-4 FairSchedulableBuilder [INFO] Added task set TaskSet_0 tasks to pool default
2014-07-21 18:16:42 main JawsController$ [INFO] Initializing...
2014-07-21 18:16:49 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:16:49 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:16:54 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:16:54 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:16:55 spark-akka.actor.default-dispatcher-3 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:16:55 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Starting remoting
2014-07-21 18:16:55 spark-akka.actor.default-dispatcher-2 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:58261]
2014-07-21 18:16:55 spark-akka.actor.default-dispatcher-2 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:58261]
2014-07-21 18:16:55 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:16:55 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:16:55 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721181655-81d7
2014-07-21 18:16:55 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:16:55 main ConnectionManager [INFO] Bound socket to port 37828 with id = ConnectionManagerId(5.5.21.123,37828)
2014-07-21 18:16:55 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:16:55 spark-akka.actor.default-dispatcher-2 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:37828 with 1061.8 MB RAM
2014-07-21 18:16:55 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:16:55 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:16:55 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:16:55 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:60996
2014-07-21 18:16:55 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:60996
2014-07-21 18:16:55 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-48710479-737b-4cea-9196-9967af4be7e3
2014-07-21 18:16:55 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:16:55 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:16:55 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:45903
2014-07-21 18:17:01 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:17:01 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:17:01 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:17:02 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:17:02 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:45903/jars/test-app.jar with timestamp 1405955822293
2014-07-21 18:17:02 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:17:02 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:17:02 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:17:02 spark-akka.actor.default-dispatcher-5 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721151705-0005
2014-07-21 18:17:02 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor added: app-20140721151705-0005/0 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:17:02 spark-akka.actor.default-dispatcher-5 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151705-0005/0 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:17:02 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor added: app-20140721151705-0005/1 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:17:02 spark-akka.actor.default-dispatcher-5 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151705-0005/1 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:17:02 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor updated: app-20140721151705-0005/0 is now RUNNING
2014-07-21 18:17:03 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor updated: app-20140721151705-0005/1 is now RUNNING
2014-07-21 18:17:03 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:17:03 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:17:03 main ParseDriver [INFO] Parse Completed
2014-07-21 18:17:03 main Analyzer [INFO] Max iterations (2) reached for batch MultiInstanceRelations
2014-07-21 18:17:03 main Analyzer [INFO] Max iterations (2) reached for batch CaseInsensitiveAttributeReferences
2014-07-21 18:17:03 main Analyzer [INFO] Max iterations (2) reached for batch Check Analysis
2014-07-21 18:17:03 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Add exchange
2014-07-21 18:17:03 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Prepare Expressions
2014-07-21 18:17:03 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:17:03 main Driver [INFO] <PERFLOG method=Driver.run>
2014-07-21 18:17:03 main Driver [INFO] <PERFLOG method=TimeToSubmit>
2014-07-21 18:17:03 main Driver [INFO] <PERFLOG method=compile>
2014-07-21 18:17:03 main Driver [INFO] <PERFLOG method=parse>
2014-07-21 18:17:03 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:17:03 main ParseDriver [INFO] Parse Completed
2014-07-21 18:17:03 main Driver [INFO] </PERFLOG method=parse start=1405955823845 end=1405955823845 duration=0>
2014-07-21 18:17:03 main Driver [INFO] <PERFLOG method=semanticAnalyze>
2014-07-21 18:17:03 main Driver [INFO] Semantic Analysis Completed
2014-07-21 18:17:03 main Driver [INFO] </PERFLOG method=semanticAnalyze start=1405955823845 end=1405955823956 duration=111>
2014-07-21 18:17:04 main ListSinkOperator [INFO] Initializing Self 0 OP
2014-07-21 18:17:04 main ListSinkOperator [INFO] Operator 0 OP initialized
2014-07-21 18:17:04 main ListSinkOperator [INFO] Initialization Done 0 OP
2014-07-21 18:17:04 main Driver [INFO] Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
2014-07-21 18:17:04 main Driver [INFO] </PERFLOG method=compile start=1405955823823 end=1405955824023 duration=200>
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:host.name=ema-Latitude-E6530
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:java.version=1.7.0_51
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:java.vendor=Oracle Corporation
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:java.home=/usr/lib/jvm/jdk1.7.0/jre
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:java.class.path=/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/classes:/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-classes:/root/.m2/repository/io/spray/spray-client/1.2.1/spray-client-1.2.1.jar:/root/.m2/repository/io/spray/spray-http/1.2.1/spray-http-1.2.1.jar:/root/.m2/repository/io/spray/spray-httpx/1.2.1/spray-httpx-1.2.1.jar:/root/.m2/repository/org/jvnet/mimepull/mimepull/1.9.4/mimepull-1.9.4.jar:/root/.m2/repository/io/spray/spray-util/1.2.1/spray-util-1.2.1.jar:/root/.m2/repository/org/scalamock/scalamock-scalatest-support_2.10/3.1.RC1/scalamock-scalatest-support_2.10-3.1.RC1.jar:/root/.m2/repository/org/scalamock/scalamock-core_2.10/3.1.RC1/scalamock-core_2.10-3.1.RC1.jar:/root/.m2/repository/org/scala-lang/scala-reflect/2.10.0/scala-reflect-2.10.0.jar:/root/.m2/repository/org/scalatest/scalatest_2.10/2.0/scalatest_2.10-2.0.jar:/root/.m2/repository/junit/junit/4.4/junit-4.4.jar:/root/.m2/repository/io/spray/spray-routing/1.2.1/spray-routing-1.2.1.jar:/root/.m2/repository/com/chuusai/shapeless_2.10/1.2.4/shapeless_2.10-1.2.4.jar:/root/.m2/repository/io/spray/spray-can/1.2.1/spray-can-1.2.1.jar:/root/.m2/repository/io/spray/spray-io/1.2.1/spray-io-1.2.1.jar:/root/.m2/repository/io/spray/spray-caching/1.2.1/spray-caching-1.2.1.jar:/root/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.3/jsr305-2.0.3.jar:/root/.m2/repository/org/tachyonproject/tachyon/0.4.1-thrift/tachyon-0.4.1-thrift.jar:/root/.m2/repository/org/apache/ant/ant/1.9.0/ant-1.9.0.jar:/root/.m2/repository/org/apache/ant/ant-launcher/1.9.0/ant-launcher-1.9.0.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jsp/7.6.8.v20121106/jetty-jsp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp/2.1.0.v201105211820/javax.servlet.jsp-2.1.0.v201105211820.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.jasper.glassfish/2.1.0.v201110031002/org.apache.jasper.glassfish-2.1.0.v201110031002.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp.jstl/1.2.0.v201105211821/javax.servlet.jsp.jstl-1.2.0.v201105211821.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.taglibs.standard.glassfish/1.2.0.v201112081803/org.apache.taglibs.standard.glassfish-1.2.0.v201112081803.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.el/2.1.0.v201105211819/javax.el-2.1.0.v201105211819.jar:/root/.m2/repository/org/eclipse/jetty/orbit/com.sun.el/1.0.0.v201105211818/com.sun.el-1.0.0.v201105211818.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.eclipse.jdt.core/3.7.1/org.eclipse.jdt.core-3.7.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-webapp/7.6.8.v20121106/jetty-webapp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-xml/7.6.8.v20121106/jetty-xml-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-servlet/7.6.8.v20121106/jetty-servlet-7.6.8.v20121106.jar:/root/.m2/repository/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.2/slf4j-log4j12-1.7.2.jar:/root/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/.m2/repository/org/apache/commons/commons-lang3/3.0/commons-lang3-3.0.jar:/root/.m2/repository/org/apache/curator/curator-recipes/2.1.0-incubating/curator-recipes-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-framework/2.1.0-incubating/curator-framework-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-client/2.1.0-incubating/curator-client-2.1.0-incubating.jar:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/root/.m2/repository/org/java-websocket/Java-WebSocket/1.3.0/Java-WebSocket-1.3.0.jar:/root/.m2/repository/org/apache/spark/spark-core_2.10/1.0.1/spark-core_2.10-1.0.1.jar:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/root/.m2/repository/commons-codec/commons-codec/1.3/commons-codec-1.3.jar:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-plus/8.1.14.v20131031/jetty-plus-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.transaction/1.1.1.v201105210645/javax.transaction-1.1.1.v201105210645.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jndi/8.1.14.v20131031/jetty-jndi-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.mail.glassfish/1.4.1.v201005082020/javax.mail.glassfish-1.4.1.v201005082020.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.activation/1.1.0.v201105071233/javax.activation-1.1.0.v201105071233.jar:/root/.m2/repository/org/eclipse/jetty/jetty-security/8.1.14.v20131031/jetty-security-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/root/.m2/repository/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar:/root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/root/.m2/repository/org/slf4j/jul-to-slf4j/1.7.5/jul-to-slf4j-1.7.5.jar:/root/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.5/jcl-over-slf4j-1.7.5.jar:/root/.m2/repository/com/ning/compress-lzf/1.0.0/compress-lzf-1.0.0.jar:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/root/.m2/repository/com/twitter/chill_2.10/0.3.6/chill_2.10-0.3.6.jar:/root/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/.m2/repository/com/twitter/chill-java/0.3.6/chill-java-0.3.6.jar:/root/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/root/.m2/repository/org/spark-project/akka/akka-remote_2.10/2.2.3-shaded-protobuf/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/spark-project/akka/akka-actor_2.10/2.2.3-shaded-protobuf/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/com/typesafe/config/1.0.2/config-1.0.2.jar:/root/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar:/root/.m2/repository/org/spark-project/protobuf/protobuf-java/2.4.1-shaded/protobuf-java-2.4.1-shaded.jar:/root/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/root/.m2/repository/org/spark-project/akka/akka-slf4j_2.10/2.2.3-shaded-protobuf/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.6/json4s-jackson_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-core_2.10/3.2.6/json4s-core_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-ast_2.10/3.2.6/json4s-ast_2.10-3.2.6.jar:/root/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/root/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/root/.m2/repository/colt/colt/1.2.0/colt-1.2.0.jar:/root/.m2/repository/concurrent/concurrent/1.3.4/concurrent-1.3.4.jar:/root/.m2/repository/org/apache/mesos/mesos/0.18.1/mesos-0.18.1-shaded-protobuf.jar:/root/.m2/repository/io/netty/netty-all/4.0.17.Final/netty-all-4.0.17.Final.jar:/root/.m2/repository/com/clearspring/analytics/stream/2.5.1/stream-2.5.1.jar:/root/.m2/repository/com/codahale/metrics/metrics-core/3.0.0/metrics-core-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-jvm/3.0.0/metrics-jvm-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-json/3.0.0/metrics-json-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-graphite/3.0.0/metrics-graphite-3.0.0.jar:/root/.m2/repository/org/spark-project/pyrolite/2.0.1/pyrolite-2.0.1.jar:/root/.m2/repository/net/sf/py4j/py4j/0.8.1/py4j-0.8.1.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.3.2/jackson-annotations-2.3.2.jar:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.3.0-mr1-cdh5.1.0/hadoop-client-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.3.0-cdh5.1.0/hadoop-common-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.3.0-cdh5.1.0/hadoop-annotations-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.3.0-cdh5.1.0/hadoop-auth-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/root/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.3.0-cdh5.1.0/hadoop-hdfs-2.3.0-cdh5.1.0.jar:/root/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/.m2/repository/org/apache/hadoop/hadoop-core/2.3.0-mr1-cdh5.1.0/hadoop-core-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/.m2/repository/org/springframework/spring-context/3.0.5.RELEASE/spring-context-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-aop/3.0.5.RELEASE/spring-aop-3.0.5.RELEASE.jar:/root/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/.m2/repository/org/springframework/spring-beans/3.0.5.RELEASE/spring-beans-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-core/3.0.5.RELEASE/spring-core-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-expression/3.0.5.RELEASE/spring-expression-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-asm/3.0.5.RELEASE/spring-asm-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/data/spring-data-hadoop/1.0.0.RELEASE/spring-data-hadoop-1.0.0.RELEASE.jar:/root/.m2/repository/org/apache/hadoop/hadoop-streaming/1.0.4/hadoop-streaming-1.0.4.jar:/root/.m2/repository/org/apache/hadoop/hadoop-tools/1.0.4/hadoop-tools-1.0.4.jar:/root/.m2/repository/org/springframework/spring-context-support/3.0.7.RELEASE/spring-context-support-3.0.7.RELEASE.jar:/root/.m2/repository/org/springframework/spring-jdbc/3.2.3.RELEASE/spring-jdbc-3.2.3.RELEASE.jar:/root/.m2/repository/org/springframework/spring-tx/3.2.3.RELEASE/spring-tx-3.2.3.RELEASE.jar:/root/.m2/repository/io/spray/spray-json_2.10/1.2.6/spray-json_2.10-1.2.6.jar:/root/.m2/repository/org/parboiled/parboiled-scala_2.10/1.1.6/parboiled-scala_2.10-1.1.6.jar:/root/.m2/repository/org/parboiled/parboiled-core/1.1.6/parboiled-core-1.1.6.jar:/root/.m2/repository/org/apache/spark/spark-sql_2.10/1.0.1/spark-sql_2.10-1.0.1.jar:/root/.m2/repository/org/apache/spark/spark-catalyst_2.10/1.0.1/spark-catalyst_2.10-1.0.1.jar:/root/.m2/repository/com/typesafe/scalalogging-slf4j_2.10/1.0.1/scalalogging-slf4j_2.10-1.0.1.jar:/root/.m2/repository/com/twitter/parquet-column/1.4.3/parquet-column-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-common/1.4.3/parquet-common-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-encoding/1.4.3/parquet-encoding-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-generator/1.4.3/parquet-generator-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-hadoop/1.4.3/parquet-hadoop-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-format/2.0.0/parquet-format-2.0.0.jar:/root/.m2/repository/com/twitter/parquet-jackson/1.4.3/parquet-jackson-1.4.3.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.3.0/jackson-databind-2.3.0.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.3.0/jackson-core-2.3.0.jar:/root/.m2/repository/org/apache/spark/spark-hive_2.10/1.0.1/spark-hive_2.10-1.0.1.jar:/root/.m2/repository/org/spark-project/hive/hive-metastore/0.12.0/hive-metastore-0.12.0.jar:/root/.m2/repository/org/antlr/antlr/3.4/antlr-3.4.jar:/root/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/root/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/root/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/root/.m2/repository/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar:/root/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/root/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar:/root/.m2/repository/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar:/root/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar:/root/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/root/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/root/.m2/repository/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar:/root/.m2/repository/org/spark-project/hive/hive-exec/0.12.0/hive-exec-0.12.0.jar:/root/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/root/.m2/repository/org/json/json/20090211/json-20090211.jar:/root/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/root/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/root/.m2/repository/org/spark-project/hive/hive-serde/0.12.0/hive-serde-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-common/0.12.0/hive-common-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-shims/0.12.0/hive-shims-0.12.0.jar:/root/.m2/repository/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar:/root/.m2/repository/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar:/root/.m2/repository/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar:/root/.m2/repository/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar:/root/.m2/repository/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar:/root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/root/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/root/.m2/repository/org/apache/avro/avro/1.7.6/avro-1.7.6.jar:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:java.io.tmpdir=/tmp
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:java.compiler=<NA>
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:os.name=Linux
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:os.arch=amd64
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:os.version=3.8.0-26-generic
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:user.name=root
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:user.home=/root
2014-07-21 18:17:04 main ZooKeeper [INFO] Client environment:user.dir=/home/ema/work/jawsGit/http-spark-sql-server/test-project
2014-07-21 18:17:04 main ZooKeeper [INFO] Initiating client connection, connectString=10.0.2.16,10.0.2.18,10.0.2.17:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@53899f3c
2014-07-21 18:17:04 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Opening socket connection to server ip-10-0-2-17/10.0.2.17:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-21 18:17:04 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Socket connection established to ip-10-0-2-17/10.0.2.17:2181, initiating session
2014-07-21 18:17:04 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Session establishment complete on server ip-10-0-2-17/10.0.2.17:2181, sessionid = 0x34758d19e5d00fb, negotiated timeout = 40000
2014-07-21 18:17:04 main Driver [INFO] <PERFLOG method=acquireReadWriteLocks>
2014-07-21 18:17:04 main Driver [INFO] </PERFLOG method=acquireReadWriteLocks start=1405955824343 end=1405955824343 duration=0>
2014-07-21 18:17:04 main Driver [INFO] <PERFLOG method=Driver.execute>
2014-07-21 18:17:04 main Driver [INFO] Starting command: show databases
2014-07-21 18:17:04 main Driver [INFO] </PERFLOG method=TimeToSubmit start=1405955823823 end=1405955824354 duration=531>
2014-07-21 18:17:04 main Driver [INFO] <PERFLOG method=runTasks>
2014-07-21 18:17:04 main Driver [INFO] <PERFLOG method=task.DDL.Stage-0>
2014-07-21 18:17:04 main metastore [INFO] Trying to connect to metastore with URI thrift://10.0.2.16:9083
2014-07-21 18:17:04 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:17:05 main metastore [INFO] Connected to metastore.
2014-07-21 18:17:05 main DDLTask [INFO] results : 1
2014-07-21 18:17:05 main Driver [INFO] </PERFLOG method=task.DDL.Stage-0 start=1405955824355 end=1405955825872 duration=1517>
2014-07-21 18:17:05 main Driver [INFO] </PERFLOG method=runTasks start=1405955824355 end=1405955825872 duration=1517>
2014-07-21 18:17:05 main Driver [INFO] </PERFLOG method=Driver.execute start=1405955824343 end=1405955825873 duration=1530>
2014-07-21 18:17:05 main Driver [INFO] OK
2014-07-21 18:17:05 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:17:05 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955825877 end=1405955825877 duration=0>
2014-07-21 18:17:05 main Driver [INFO] </PERFLOG method=Driver.run start=1405955823823 end=1405955825877 duration=2054>
2014-07-21 18:17:05 main FileInputFormat [INFO] Total input paths to process : 1
2014-07-21 18:17:05 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:17:05 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955825910 end=1405955825911 duration=1>
2014-07-21 18:17:06 main ZooKeeper [INFO] Session: 0x34758d19e5d00fb closed
2014-07-21 18:17:06 main-EventThread ClientCnxn [INFO] EventThread shut down
2014-07-21 18:17:06 main SparkContext [INFO] Starting job: collect at SparkPlan.scala:52
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Got job 0 (collect at SparkPlan.scala:52) with 1 output partitions (allowLocal=false)
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Final stage: Stage 0(collect at SparkPlan.scala:52)
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Parents of final stage: List()
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Missing parents: List()
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Submitting Stage 0 (MappedRDD[4] at map at SparkPlan.scala:52), which has no missing parents
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Submitting 1 missing tasks from Stage 0 (MappedRDD[4] at map at SparkPlan.scala:52)
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 TaskSchedulerImpl [INFO] Adding task set 0.0 with 1 tasks
2014-07-21 18:17:06 spark-akka.actor.default-dispatcher-3 FairSchedulableBuilder [INFO] Added task set TaskSet_0 tasks to pool default
2014-07-21 18:17:21 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:17:36 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:17:51 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:18:06 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721151705-0005/0 is now EXITED (Command exited with code 1)
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Executor app-20140721151705-0005/0 removed: Command exited with code 1
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor added: app-20140721151705-0005/2 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-5 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151705-0005/2 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor updated: app-20140721151705-0005/2 is now RUNNING
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor updated: app-20140721151705-0005/1 is now EXITED (Command exited with code 1)
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-5 SparkDeploySchedulerBackend [INFO] Executor app-20140721151705-0005/1 removed: Command exited with code 1
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor added: app-20140721151705-0005/3 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:18:09 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151705-0005/3 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:18:10 spark-akka.actor.default-dispatcher-5 AppClient$ClientActor [INFO] Executor updated: app-20140721151705-0005/3 is now RUNNING
2014-07-21 18:18:21 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:18:36 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:18:51 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:19:06 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:19:37 main JawsController$ [INFO] Initializing...
2014-07-21 18:19:44 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:19:44 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:19:49 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:19:49 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:19:49 spark-akka.actor.default-dispatcher-4 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:19:49 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Starting remoting
2014-07-21 18:19:49 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:60296]
2014-07-21 18:19:49 spark-akka.actor.default-dispatcher-4 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:60296]
2014-07-21 18:19:49 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:19:49 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:19:49 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721181949-366e
2014-07-21 18:19:49 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:19:49 main ConnectionManager [INFO] Bound socket to port 34452 with id = ConnectionManagerId(5.5.21.123,34452)
2014-07-21 18:19:49 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:19:49 spark-akka.actor.default-dispatcher-3 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:34452 with 1061.8 MB RAM
2014-07-21 18:19:49 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:19:50 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:19:50 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:19:50 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:35868
2014-07-21 18:19:50 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:35868
2014-07-21 18:19:50 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-4e893dd9-05c4-4d38-8cd5-abf953b7b017
2014-07-21 18:19:50 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:19:50 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:19:50 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:37496
2014-07-21 18:19:55 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:19:55 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:19:55 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:19:55 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:19:55 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:37496/jars/test-app.jar with timestamp 1405955995763
2014-07-21 18:19:55 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:19:55 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:19:56 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:19:56 spark-akka.actor.default-dispatcher-2 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721151958-0006
2014-07-21 18:19:56 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor added: app-20140721151958-0006/0 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:19:56 spark-akka.actor.default-dispatcher-2 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151958-0006/0 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:19:56 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor added: app-20140721151958-0006/1 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:19:56 spark-akka.actor.default-dispatcher-2 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721151958-0006/1 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:19:56 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor updated: app-20140721151958-0006/0 is now RUNNING
2014-07-21 18:19:56 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor updated: app-20140721151958-0006/1 is now RUNNING
2014-07-21 18:19:56 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:19:56 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:19:56 main ParseDriver [INFO] Parse Completed
2014-07-21 18:19:57 main Analyzer [INFO] Max iterations (2) reached for batch MultiInstanceRelations
2014-07-21 18:19:57 main Analyzer [INFO] Max iterations (2) reached for batch CaseInsensitiveAttributeReferences
2014-07-21 18:19:57 main Analyzer [INFO] Max iterations (2) reached for batch Check Analysis
2014-07-21 18:19:57 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Add exchange
2014-07-21 18:19:57 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Prepare Expressions
2014-07-21 18:19:57 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=Driver.run>
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=TimeToSubmit>
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=compile>
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=parse>
2014-07-21 18:19:57 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:19:57 main ParseDriver [INFO] Parse Completed
2014-07-21 18:19:57 main Driver [INFO] </PERFLOG method=parse start=1405955997289 end=1405955997290 duration=1>
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=semanticAnalyze>
2014-07-21 18:19:57 main Driver [INFO] Semantic Analysis Completed
2014-07-21 18:19:57 main Driver [INFO] </PERFLOG method=semanticAnalyze start=1405955997290 end=1405955997396 duration=106>
2014-07-21 18:19:57 main ListSinkOperator [INFO] Initializing Self 0 OP
2014-07-21 18:19:57 main ListSinkOperator [INFO] Operator 0 OP initialized
2014-07-21 18:19:57 main ListSinkOperator [INFO] Initialization Done 0 OP
2014-07-21 18:19:57 main Driver [INFO] Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
2014-07-21 18:19:57 main Driver [INFO] </PERFLOG method=compile start=1405955997268 end=1405955997461 duration=193>
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:host.name=ema-Latitude-E6530
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:java.version=1.7.0_51
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:java.vendor=Oracle Corporation
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:java.home=/usr/lib/jvm/jdk1.7.0/jre
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:java.class.path=/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/classes:/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-classes:/root/.m2/repository/io/spray/spray-client/1.2.1/spray-client-1.2.1.jar:/root/.m2/repository/io/spray/spray-http/1.2.1/spray-http-1.2.1.jar:/root/.m2/repository/io/spray/spray-httpx/1.2.1/spray-httpx-1.2.1.jar:/root/.m2/repository/org/jvnet/mimepull/mimepull/1.9.4/mimepull-1.9.4.jar:/root/.m2/repository/io/spray/spray-util/1.2.1/spray-util-1.2.1.jar:/root/.m2/repository/org/scalamock/scalamock-scalatest-support_2.10/3.1.RC1/scalamock-scalatest-support_2.10-3.1.RC1.jar:/root/.m2/repository/org/scalamock/scalamock-core_2.10/3.1.RC1/scalamock-core_2.10-3.1.RC1.jar:/root/.m2/repository/org/scala-lang/scala-reflect/2.10.0/scala-reflect-2.10.0.jar:/root/.m2/repository/org/scalatest/scalatest_2.10/2.0/scalatest_2.10-2.0.jar:/root/.m2/repository/junit/junit/4.4/junit-4.4.jar:/root/.m2/repository/io/spray/spray-routing/1.2.1/spray-routing-1.2.1.jar:/root/.m2/repository/com/chuusai/shapeless_2.10/1.2.4/shapeless_2.10-1.2.4.jar:/root/.m2/repository/io/spray/spray-can/1.2.1/spray-can-1.2.1.jar:/root/.m2/repository/io/spray/spray-io/1.2.1/spray-io-1.2.1.jar:/root/.m2/repository/io/spray/spray-caching/1.2.1/spray-caching-1.2.1.jar:/root/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.3/jsr305-2.0.3.jar:/root/.m2/repository/org/tachyonproject/tachyon/0.4.1-thrift/tachyon-0.4.1-thrift.jar:/root/.m2/repository/org/apache/ant/ant/1.9.0/ant-1.9.0.jar:/root/.m2/repository/org/apache/ant/ant-launcher/1.9.0/ant-launcher-1.9.0.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jsp/7.6.8.v20121106/jetty-jsp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp/2.1.0.v201105211820/javax.servlet.jsp-2.1.0.v201105211820.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.jasper.glassfish/2.1.0.v201110031002/org.apache.jasper.glassfish-2.1.0.v201110031002.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp.jstl/1.2.0.v201105211821/javax.servlet.jsp.jstl-1.2.0.v201105211821.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.taglibs.standard.glassfish/1.2.0.v201112081803/org.apache.taglibs.standard.glassfish-1.2.0.v201112081803.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.el/2.1.0.v201105211819/javax.el-2.1.0.v201105211819.jar:/root/.m2/repository/org/eclipse/jetty/orbit/com.sun.el/1.0.0.v201105211818/com.sun.el-1.0.0.v201105211818.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.eclipse.jdt.core/3.7.1/org.eclipse.jdt.core-3.7.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-webapp/7.6.8.v20121106/jetty-webapp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-xml/7.6.8.v20121106/jetty-xml-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-servlet/7.6.8.v20121106/jetty-servlet-7.6.8.v20121106.jar:/root/.m2/repository/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.2/slf4j-log4j12-1.7.2.jar:/root/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/.m2/repository/org/apache/commons/commons-lang3/3.0/commons-lang3-3.0.jar:/root/.m2/repository/org/apache/curator/curator-recipes/2.1.0-incubating/curator-recipes-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-framework/2.1.0-incubating/curator-framework-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-client/2.1.0-incubating/curator-client-2.1.0-incubating.jar:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/root/.m2/repository/org/java-websocket/Java-WebSocket/1.3.0/Java-WebSocket-1.3.0.jar:/root/.m2/repository/org/apache/spark/spark-core_2.10/1.0.1/spark-core_2.10-1.0.1.jar:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/root/.m2/repository/commons-codec/commons-codec/1.3/commons-codec-1.3.jar:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-plus/8.1.14.v20131031/jetty-plus-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.transaction/1.1.1.v201105210645/javax.transaction-1.1.1.v201105210645.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jndi/8.1.14.v20131031/jetty-jndi-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.mail.glassfish/1.4.1.v201005082020/javax.mail.glassfish-1.4.1.v201005082020.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.activation/1.1.0.v201105071233/javax.activation-1.1.0.v201105071233.jar:/root/.m2/repository/org/eclipse/jetty/jetty-security/8.1.14.v20131031/jetty-security-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/root/.m2/repository/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar:/root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/root/.m2/repository/org/slf4j/jul-to-slf4j/1.7.5/jul-to-slf4j-1.7.5.jar:/root/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.5/jcl-over-slf4j-1.7.5.jar:/root/.m2/repository/com/ning/compress-lzf/1.0.0/compress-lzf-1.0.0.jar:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/root/.m2/repository/com/twitter/chill_2.10/0.3.6/chill_2.10-0.3.6.jar:/root/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/.m2/repository/com/twitter/chill-java/0.3.6/chill-java-0.3.6.jar:/root/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/root/.m2/repository/org/spark-project/akka/akka-remote_2.10/2.2.3-shaded-protobuf/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/spark-project/akka/akka-actor_2.10/2.2.3-shaded-protobuf/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/com/typesafe/config/1.0.2/config-1.0.2.jar:/root/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar:/root/.m2/repository/org/spark-project/protobuf/protobuf-java/2.4.1-shaded/protobuf-java-2.4.1-shaded.jar:/root/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/root/.m2/repository/org/spark-project/akka/akka-slf4j_2.10/2.2.3-shaded-protobuf/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.6/json4s-jackson_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-core_2.10/3.2.6/json4s-core_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-ast_2.10/3.2.6/json4s-ast_2.10-3.2.6.jar:/root/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/root/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/root/.m2/repository/colt/colt/1.2.0/colt-1.2.0.jar:/root/.m2/repository/concurrent/concurrent/1.3.4/concurrent-1.3.4.jar:/root/.m2/repository/org/apache/mesos/mesos/0.18.1/mesos-0.18.1-shaded-protobuf.jar:/root/.m2/repository/io/netty/netty-all/4.0.17.Final/netty-all-4.0.17.Final.jar:/root/.m2/repository/com/clearspring/analytics/stream/2.5.1/stream-2.5.1.jar:/root/.m2/repository/com/codahale/metrics/metrics-core/3.0.0/metrics-core-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-jvm/3.0.0/metrics-jvm-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-json/3.0.0/metrics-json-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-graphite/3.0.0/metrics-graphite-3.0.0.jar:/root/.m2/repository/org/spark-project/pyrolite/2.0.1/pyrolite-2.0.1.jar:/root/.m2/repository/net/sf/py4j/py4j/0.8.1/py4j-0.8.1.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.3.2/jackson-annotations-2.3.2.jar:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.3.0-mr1-cdh5.1.0/hadoop-client-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.3.0-cdh5.1.0/hadoop-common-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.3.0-cdh5.1.0/hadoop-annotations-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.3.0-cdh5.1.0/hadoop-auth-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/root/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.3.0-cdh5.1.0/hadoop-hdfs-2.3.0-cdh5.1.0.jar:/root/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/.m2/repository/org/apache/hadoop/hadoop-core/2.3.0-mr1-cdh5.1.0/hadoop-core-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/.m2/repository/org/springframework/spring-context/3.0.5.RELEASE/spring-context-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-aop/3.0.5.RELEASE/spring-aop-3.0.5.RELEASE.jar:/root/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/.m2/repository/org/springframework/spring-beans/3.0.5.RELEASE/spring-beans-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-core/3.0.5.RELEASE/spring-core-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-expression/3.0.5.RELEASE/spring-expression-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-asm/3.0.5.RELEASE/spring-asm-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/data/spring-data-hadoop/1.0.0.RELEASE/spring-data-hadoop-1.0.0.RELEASE.jar:/root/.m2/repository/org/apache/hadoop/hadoop-streaming/1.0.4/hadoop-streaming-1.0.4.jar:/root/.m2/repository/org/apache/hadoop/hadoop-tools/1.0.4/hadoop-tools-1.0.4.jar:/root/.m2/repository/org/springframework/spring-context-support/3.0.7.RELEASE/spring-context-support-3.0.7.RELEASE.jar:/root/.m2/repository/org/springframework/spring-jdbc/3.2.3.RELEASE/spring-jdbc-3.2.3.RELEASE.jar:/root/.m2/repository/org/springframework/spring-tx/3.2.3.RELEASE/spring-tx-3.2.3.RELEASE.jar:/root/.m2/repository/io/spray/spray-json_2.10/1.2.6/spray-json_2.10-1.2.6.jar:/root/.m2/repository/org/parboiled/parboiled-scala_2.10/1.1.6/parboiled-scala_2.10-1.1.6.jar:/root/.m2/repository/org/parboiled/parboiled-core/1.1.6/parboiled-core-1.1.6.jar:/root/.m2/repository/org/apache/spark/spark-sql_2.10/1.0.1/spark-sql_2.10-1.0.1.jar:/root/.m2/repository/org/apache/spark/spark-catalyst_2.10/1.0.1/spark-catalyst_2.10-1.0.1.jar:/root/.m2/repository/com/typesafe/scalalogging-slf4j_2.10/1.0.1/scalalogging-slf4j_2.10-1.0.1.jar:/root/.m2/repository/com/twitter/parquet-column/1.4.3/parquet-column-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-common/1.4.3/parquet-common-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-encoding/1.4.3/parquet-encoding-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-generator/1.4.3/parquet-generator-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-hadoop/1.4.3/parquet-hadoop-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-format/2.0.0/parquet-format-2.0.0.jar:/root/.m2/repository/com/twitter/parquet-jackson/1.4.3/parquet-jackson-1.4.3.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.3.0/jackson-databind-2.3.0.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.3.0/jackson-core-2.3.0.jar:/root/.m2/repository/org/apache/spark/spark-hive_2.10/1.0.1/spark-hive_2.10-1.0.1.jar:/root/.m2/repository/org/spark-project/hive/hive-metastore/0.12.0/hive-metastore-0.12.0.jar:/root/.m2/repository/org/antlr/antlr/3.4/antlr-3.4.jar:/root/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/root/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/root/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/root/.m2/repository/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar:/root/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/root/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar:/root/.m2/repository/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar:/root/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar:/root/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/root/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/root/.m2/repository/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar:/root/.m2/repository/org/spark-project/hive/hive-exec/0.12.0/hive-exec-0.12.0.jar:/root/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/root/.m2/repository/org/json/json/20090211/json-20090211.jar:/root/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/root/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/root/.m2/repository/org/spark-project/hive/hive-serde/0.12.0/hive-serde-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-common/0.12.0/hive-common-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-shims/0.12.0/hive-shims-0.12.0.jar:/root/.m2/repository/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar:/root/.m2/repository/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar:/root/.m2/repository/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar:/root/.m2/repository/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar:/root/.m2/repository/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar:/root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/root/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/root/.m2/repository/org/apache/avro/avro/1.7.6/avro-1.7.6.jar:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:java.io.tmpdir=/tmp
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:java.compiler=<NA>
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:os.name=Linux
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:os.arch=amd64
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:os.version=3.8.0-26-generic
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:user.name=root
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:user.home=/root
2014-07-21 18:19:57 main ZooKeeper [INFO] Client environment:user.dir=/home/ema/work/jawsGit/http-spark-sql-server/test-project
2014-07-21 18:19:57 main ZooKeeper [INFO] Initiating client connection, connectString=10.0.2.16,10.0.2.18,10.0.2.17:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@ebbecf8
2014-07-21 18:19:57 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Opening socket connection to server ip-10-0-2-17/10.0.2.17:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-21 18:19:57 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Socket connection established to ip-10-0-2-17/10.0.2.17:2181, initiating session
2014-07-21 18:19:57 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Session establishment complete on server ip-10-0-2-17/10.0.2.17:2181, sessionid = 0x34758d19e5d00ff, negotiated timeout = 40000
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=acquireReadWriteLocks>
2014-07-21 18:19:57 main Driver [INFO] </PERFLOG method=acquireReadWriteLocks start=1405955997779 end=1405955997779 duration=0>
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=Driver.execute>
2014-07-21 18:19:57 main Driver [INFO] Starting command: show databases
2014-07-21 18:19:57 main Driver [INFO] </PERFLOG method=TimeToSubmit start=1405955997268 end=1405955997790 duration=522>
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=runTasks>
2014-07-21 18:19:57 main Driver [INFO] <PERFLOG method=task.DDL.Stage-0>
2014-07-21 18:19:57 main metastore [INFO] Trying to connect to metastore with URI thrift://10.0.2.16:9083
2014-07-21 18:19:58 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:19:59 main metastore [INFO] Connected to metastore.
2014-07-21 18:19:59 main DDLTask [INFO] results : 1
2014-07-21 18:19:59 main Driver [INFO] </PERFLOG method=task.DDL.Stage-0 start=1405955997791 end=1405955999271 duration=1480>
2014-07-21 18:19:59 main Driver [INFO] </PERFLOG method=runTasks start=1405955997790 end=1405955999271 duration=1481>
2014-07-21 18:19:59 main Driver [INFO] </PERFLOG method=Driver.execute start=1405955997779 end=1405955999272 duration=1493>
2014-07-21 18:19:59 main Driver [INFO] OK
2014-07-21 18:19:59 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:19:59 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955999276 end=1405955999276 duration=0>
2014-07-21 18:19:59 main Driver [INFO] </PERFLOG method=Driver.run start=1405955997268 end=1405955999276 duration=2008>
2014-07-21 18:19:59 main FileInputFormat [INFO] Total input paths to process : 1
2014-07-21 18:19:59 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:19:59 main Driver [INFO] </PERFLOG method=releaseLocks start=1405955999310 end=1405955999310 duration=0>
2014-07-21 18:19:59 main ZooKeeper [INFO] Session: 0x34758d19e5d00ff closed
2014-07-21 18:19:59 main-EventThread ClientCnxn [INFO] EventThread shut down
2014-07-21 18:19:59 main SparkContext [INFO] Starting job: collect at SparkPlan.scala:52
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 DAGScheduler [INFO] Got job 0 (collect at SparkPlan.scala:52) with 1 output partitions (allowLocal=false)
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 DAGScheduler [INFO] Final stage: Stage 0(collect at SparkPlan.scala:52)
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 DAGScheduler [INFO] Parents of final stage: List()
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 DAGScheduler [INFO] Missing parents: List()
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 DAGScheduler [INFO] Submitting Stage 0 (MappedRDD[4] at map at SparkPlan.scala:52), which has no missing parents
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 DAGScheduler [INFO] Submitting 1 missing tasks from Stage 0 (MappedRDD[4] at map at SparkPlan.scala:52)
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 TaskSchedulerImpl [INFO] Adding task set 0.0 with 1 tasks
2014-07-21 18:19:59 spark-akka.actor.default-dispatcher-12 FairSchedulableBuilder [INFO] Added task set TaskSet_0 tasks to pool default
2014-07-21 18:20:14 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:20:29 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:23:55 main JawsController$ [INFO] Initializing...
2014-07-21 18:23:55 main Utils [WARN] Your hostname, ema-Latitude-E6530 resolves to a loopback address: 127.0.1.1; using 5.5.21.123 instead (on interface tun0)
2014-07-21 18:23:55 main Utils [WARN] Set SPARK_LOCAL_IP if you need to bind to another address
2014-07-21 18:24:00 main SecurityManager [INFO] Changing view acls to: root
2014-07-21 18:24:00 main SecurityManager [INFO] SecurityManager: authentication disabled; ui acls disabled; users with view permissions: Set(root)
2014-07-21 18:24:00 spark-akka.actor.default-dispatcher-3 Slf4jLogger [INFO] Slf4jLogger started
2014-07-21 18:24:00 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Starting remoting
2014-07-21 18:24:00 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Remoting started; listening on addresses :[akka.tcp://spark@5.5.21.123:57442]
2014-07-21 18:24:00 spark-akka.actor.default-dispatcher-3 Remoting [INFO] Remoting now listens on addresses: [akka.tcp://spark@5.5.21.123:57442]
2014-07-21 18:24:00 main SparkEnv [INFO] Registering MapOutputTracker
2014-07-21 18:24:00 main SparkEnv [INFO] Registering BlockManagerMaster
2014-07-21 18:24:00 main DiskBlockManager [INFO] Created local directory at /tmp/spark-local-20140721182400-9d7f
2014-07-21 18:24:00 main MemoryStore [INFO] MemoryStore started with capacity 1061.8 MB.
2014-07-21 18:24:00 main ConnectionManager [INFO] Bound socket to port 40797 with id = ConnectionManagerId(5.5.21.123,40797)
2014-07-21 18:24:00 main BlockManagerMaster [INFO] Trying to register BlockManager
2014-07-21 18:24:00 spark-akka.actor.default-dispatcher-3 BlockManagerInfo [INFO] Registering block manager 5.5.21.123:40797 with 1061.8 MB RAM
2014-07-21 18:24:00 main BlockManagerMaster [INFO] Registered BlockManager
2014-07-21 18:24:00 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:24:00 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:24:00 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:55602
2014-07-21 18:24:00 main HttpBroadcast [INFO] Broadcast server started at http://5.5.21.123:55602
2014-07-21 18:24:00 main HttpFileServer [INFO] HTTP File server directory is /tmp/spark-9dbcee4a-91e7-4078-8a22-c51a3cad978a
2014-07-21 18:24:00 main HttpServer [INFO] Starting HTTP Server
2014-07-21 18:24:00 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:24:00 main AbstractConnector [INFO] Started SocketConnector@0.0.0.0:37200
2014-07-21 18:24:06 main Server [INFO] jetty-8.1.14.v20131031
2014-07-21 18:24:06 main AbstractConnector [INFO] Started SelectChannelConnector@0.0.0.0:4040
2014-07-21 18:24:06 main SparkUI [INFO] Started SparkUI at http://5.5.21.123:4040
2014-07-21 18:24:06 main NativeCodeLoader [WARN] Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2014-07-21 18:24:06 main SparkContext [INFO] Added JAR /home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-app.jar at http://5.5.21.123:37200/jars/test-app.jar with timestamp 1405956246572
2014-07-21 18:24:06 main FairSchedulableBuilder [INFO] Created default pool default, schedulingMode: FIFO, minShare: 0, weight: 1
2014-07-21 18:24:06 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Connecting to master spark://10.0.2.16:7077...
2014-07-21 18:24:07 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:24:07 spark-akka.actor.default-dispatcher-5 SparkDeploySchedulerBackend [INFO] Connected to Spark cluster with app ID app-20140721152409-0007
2014-07-21 18:24:07 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Executor added: app-20140721152409-0007/0 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:24:07 spark-akka.actor.default-dispatcher-3 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721152409-0007/0 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:24:07 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Executor added: app-20140721152409-0007/1 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:24:07 spark-akka.actor.default-dispatcher-3 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721152409-0007/1 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:24:07 spark-akka.actor.default-dispatcher-3 AppClient$ClientActor [INFO] Executor updated: app-20140721152409-0007/0 is now RUNNING
2014-07-21 18:24:07 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:24:07 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721152409-0007/1 is now RUNNING
2014-07-21 18:24:07 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:24:07 main ParseDriver [INFO] Parse Completed
2014-07-21 18:24:07 main Analyzer [INFO] Max iterations (2) reached for batch MultiInstanceRelations
2014-07-21 18:24:07 main Analyzer [INFO] Max iterations (2) reached for batch CaseInsensitiveAttributeReferences
2014-07-21 18:24:07 main Analyzer [INFO] Max iterations (2) reached for batch Check Analysis
2014-07-21 18:24:08 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Add exchange
2014-07-21 18:24:08 main SQLContext$$anon$1 [INFO] Max iterations (2) reached for batch Prepare Expressions
2014-07-21 18:24:08 main HiveConf [WARN] DEPRECATED: Configuration property hive.metastore.local no longer has any effect. Make sure to provide a valid value for hive.metastore.uris if you are connecting to a remote metastore.
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=Driver.run>
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=TimeToSubmit>
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=compile>
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=parse>
2014-07-21 18:24:08 main ParseDriver [INFO] Parsing command: show databases
2014-07-21 18:24:08 main ParseDriver [INFO] Parse Completed
2014-07-21 18:24:08 main Driver [INFO] </PERFLOG method=parse start=1405956248088 end=1405956248089 duration=1>
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=semanticAnalyze>
2014-07-21 18:24:08 main Driver [INFO] Semantic Analysis Completed
2014-07-21 18:24:08 main Driver [INFO] </PERFLOG method=semanticAnalyze start=1405956248089 end=1405956248206 duration=117>
2014-07-21 18:24:08 main ListSinkOperator [INFO] Initializing Self 0 OP
2014-07-21 18:24:08 main ListSinkOperator [INFO] Operator 0 OP initialized
2014-07-21 18:24:08 main ListSinkOperator [INFO] Initialization Done 0 OP
2014-07-21 18:24:08 main Driver [INFO] Returning Hive schema: Schema(fieldSchemas:[FieldSchema(name:database_name, type:string, comment:from deserializer)], properties:null)
2014-07-21 18:24:08 main Driver [INFO] </PERFLOG method=compile start=1405956248065 end=1405956248322 duration=257>
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:zookeeper.version=3.4.5-1392090, built on 09/30/2012 17:52 GMT
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:host.name=ema-Latitude-E6530
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:java.version=1.7.0_51
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:java.vendor=Oracle Corporation
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:java.home=/usr/lib/jvm/jdk1.7.0/jre
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:java.class.path=/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/classes:/home/ema/work/jawsGit/http-spark-sql-server/test-project/target/test-classes:/root/.m2/repository/io/spray/spray-client/1.2.1/spray-client-1.2.1.jar:/root/.m2/repository/io/spray/spray-http/1.2.1/spray-http-1.2.1.jar:/root/.m2/repository/io/spray/spray-httpx/1.2.1/spray-httpx-1.2.1.jar:/root/.m2/repository/org/jvnet/mimepull/mimepull/1.9.4/mimepull-1.9.4.jar:/root/.m2/repository/io/spray/spray-util/1.2.1/spray-util-1.2.1.jar:/root/.m2/repository/org/scalamock/scalamock-scalatest-support_2.10/3.1.RC1/scalamock-scalatest-support_2.10-3.1.RC1.jar:/root/.m2/repository/org/scalamock/scalamock-core_2.10/3.1.RC1/scalamock-core_2.10-3.1.RC1.jar:/root/.m2/repository/org/scala-lang/scala-reflect/2.10.0/scala-reflect-2.10.0.jar:/root/.m2/repository/org/scalatest/scalatest_2.10/2.0/scalatest_2.10-2.0.jar:/root/.m2/repository/junit/junit/4.4/junit-4.4.jar:/root/.m2/repository/io/spray/spray-routing/1.2.1/spray-routing-1.2.1.jar:/root/.m2/repository/com/chuusai/shapeless_2.10/1.2.4/shapeless_2.10-1.2.4.jar:/root/.m2/repository/io/spray/spray-can/1.2.1/spray-can-1.2.1.jar:/root/.m2/repository/io/spray/spray-io/1.2.1/spray-io-1.2.1.jar:/root/.m2/repository/io/spray/spray-caching/1.2.1/spray-caching-1.2.1.jar:/root/.m2/repository/com/googlecode/concurrentlinkedhashmap/concurrentlinkedhashmap-lru/1.4/concurrentlinkedhashmap-lru-1.4.jar:/root/.m2/repository/com/google/code/findbugs/jsr305/2.0.3/jsr305-2.0.3.jar:/root/.m2/repository/org/tachyonproject/tachyon/0.4.1-thrift/tachyon-0.4.1-thrift.jar:/root/.m2/repository/org/apache/ant/ant/1.9.0/ant-1.9.0.jar:/root/.m2/repository/org/apache/ant/ant-launcher/1.9.0/ant-launcher-1.9.0.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jsp/7.6.8.v20121106/jetty-jsp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp/2.1.0.v201105211820/javax.servlet.jsp-2.1.0.v201105211820.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.jasper.glassfish/2.1.0.v201110031002/org.apache.jasper.glassfish-2.1.0.v201110031002.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet.jsp.jstl/1.2.0.v201105211821/javax.servlet.jsp.jstl-1.2.0.v201105211821.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.apache.taglibs.standard.glassfish/1.2.0.v201112081803/org.apache.taglibs.standard.glassfish-1.2.0.v201112081803.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.el/2.1.0.v201105211819/javax.el-2.1.0.v201105211819.jar:/root/.m2/repository/org/eclipse/jetty/orbit/com.sun.el/1.0.0.v201105211818/com.sun.el-1.0.0.v201105211818.jar:/root/.m2/repository/org/eclipse/jetty/orbit/org.eclipse.jdt.core/3.7.1/org.eclipse.jdt.core-3.7.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-webapp/7.6.8.v20121106/jetty-webapp-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-xml/7.6.8.v20121106/jetty-xml-7.6.8.v20121106.jar:/root/.m2/repository/org/eclipse/jetty/jetty-servlet/7.6.8.v20121106/jetty-servlet-7.6.8.v20121106.jar:/root/.m2/repository/org/slf4j/slf4j-api/1.7.2/slf4j-api-1.7.2.jar:/root/.m2/repository/org/slf4j/slf4j-log4j12/1.7.2/slf4j-log4j12-1.7.2.jar:/root/.m2/repository/commons-io/commons-io/2.4/commons-io-2.4.jar:/root/.m2/repository/org/apache/commons/commons-lang3/3.0/commons-lang3-3.0.jar:/root/.m2/repository/org/apache/curator/curator-recipes/2.1.0-incubating/curator-recipes-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-framework/2.1.0-incubating/curator-framework-2.1.0-incubating.jar:/root/.m2/repository/org/apache/curator/curator-client/2.1.0-incubating/curator-client-2.1.0-incubating.jar:/root/.m2/repository/org/apache/zookeeper/zookeeper/3.4.5/zookeeper-3.4.5.jar:/root/.m2/repository/org/java-websocket/Java-WebSocket/1.3.0/Java-WebSocket-1.3.0.jar:/root/.m2/repository/org/apache/spark/spark-core_2.10/1.0.1/spark-core_2.10-1.0.1.jar:/root/.m2/repository/net/java/dev/jets3t/jets3t/0.7.1/jets3t-0.7.1.jar:/root/.m2/repository/commons-codec/commons-codec/1.3/commons-codec-1.3.jar:/root/.m2/repository/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar:/root/.m2/repository/org/eclipse/jetty/jetty-plus/8.1.14.v20131031/jetty-plus-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.transaction/1.1.1.v201105210645/javax.transaction-1.1.1.v201105210645.jar:/root/.m2/repository/org/eclipse/jetty/jetty-jndi/8.1.14.v20131031/jetty-jndi-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.mail.glassfish/1.4.1.v201005082020/javax.mail.glassfish-1.4.1.v201005082020.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.activation/1.1.0.v201105071233/javax.activation-1.1.0.v201105071233.jar:/root/.m2/repository/org/eclipse/jetty/jetty-security/8.1.14.v20131031/jetty-security-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-util/8.1.14.v20131031/jetty-util-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-server/8.1.14.v20131031/jetty-server-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/orbit/javax.servlet/3.0.0.v201112011016/javax.servlet-3.0.0.v201112011016.jar:/root/.m2/repository/org/eclipse/jetty/jetty-continuation/8.1.14.v20131031/jetty-continuation-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-http/8.1.14.v20131031/jetty-http-8.1.14.v20131031.jar:/root/.m2/repository/org/eclipse/jetty/jetty-io/8.1.14.v20131031/jetty-io-8.1.14.v20131031.jar:/root/.m2/repository/com/google/guava/guava/14.0.1/guava-14.0.1.jar:/root/.m2/repository/org/slf4j/jul-to-slf4j/1.7.5/jul-to-slf4j-1.7.5.jar:/root/.m2/repository/org/slf4j/jcl-over-slf4j/1.7.5/jcl-over-slf4j-1.7.5.jar:/root/.m2/repository/com/ning/compress-lzf/1.0.0/compress-lzf-1.0.0.jar:/root/.m2/repository/org/xerial/snappy/snappy-java/1.0.5/snappy-java-1.0.5.jar:/root/.m2/repository/com/twitter/chill_2.10/0.3.6/chill_2.10-0.3.6.jar:/root/.m2/repository/com/esotericsoftware/kryo/kryo/2.21/kryo-2.21.jar:/root/.m2/repository/com/esotericsoftware/reflectasm/reflectasm/1.07/reflectasm-1.07-shaded.jar:/root/.m2/repository/com/esotericsoftware/minlog/minlog/1.2/minlog-1.2.jar:/root/.m2/repository/org/objenesis/objenesis/1.2/objenesis-1.2.jar:/root/.m2/repository/com/twitter/chill-java/0.3.6/chill-java-0.3.6.jar:/root/.m2/repository/commons-net/commons-net/2.2/commons-net-2.2.jar:/root/.m2/repository/org/spark-project/akka/akka-remote_2.10/2.2.3-shaded-protobuf/akka-remote_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/spark-project/akka/akka-actor_2.10/2.2.3-shaded-protobuf/akka-actor_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/com/typesafe/config/1.0.2/config-1.0.2.jar:/root/.m2/repository/io/netty/netty/3.6.6.Final/netty-3.6.6.Final.jar:/root/.m2/repository/org/spark-project/protobuf/protobuf-java/2.4.1-shaded/protobuf-java-2.4.1-shaded.jar:/root/.m2/repository/org/uncommons/maths/uncommons-maths/1.2.2a/uncommons-maths-1.2.2a.jar:/root/.m2/repository/org/spark-project/akka/akka-slf4j_2.10/2.2.3-shaded-protobuf/akka-slf4j_2.10-2.2.3-shaded-protobuf.jar:/root/.m2/repository/org/json4s/json4s-jackson_2.10/3.2.6/json4s-jackson_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-core_2.10/3.2.6/json4s-core_2.10-3.2.6.jar:/root/.m2/repository/org/json4s/json4s-ast_2.10/3.2.6/json4s-ast_2.10-3.2.6.jar:/root/.m2/repository/org/scala-lang/scalap/2.10.0/scalap-2.10.0.jar:/root/.m2/repository/org/scala-lang/scala-compiler/2.10.0/scala-compiler-2.10.0.jar:/root/.m2/repository/colt/colt/1.2.0/colt-1.2.0.jar:/root/.m2/repository/concurrent/concurrent/1.3.4/concurrent-1.3.4.jar:/root/.m2/repository/org/apache/mesos/mesos/0.18.1/mesos-0.18.1-shaded-protobuf.jar:/root/.m2/repository/io/netty/netty-all/4.0.17.Final/netty-all-4.0.17.Final.jar:/root/.m2/repository/com/clearspring/analytics/stream/2.5.1/stream-2.5.1.jar:/root/.m2/repository/com/codahale/metrics/metrics-core/3.0.0/metrics-core-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-jvm/3.0.0/metrics-jvm-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-json/3.0.0/metrics-json-3.0.0.jar:/root/.m2/repository/com/codahale/metrics/metrics-graphite/3.0.0/metrics-graphite-3.0.0.jar:/root/.m2/repository/org/spark-project/pyrolite/2.0.1/pyrolite-2.0.1.jar:/root/.m2/repository/net/sf/py4j/py4j/0.8.1/py4j-0.8.1.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-annotations/2.3.2/jackson-annotations-2.3.2.jar:/root/.m2/repository/commons-cli/commons-cli/1.2/commons-cli-1.2.jar:/root/.m2/repository/org/apache/hadoop/hadoop-client/2.3.0-mr1-cdh5.1.0/hadoop-client-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-common/2.3.0-cdh5.1.0/hadoop-common-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-annotations/2.3.0-cdh5.1.0/hadoop-annotations-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/commons/commons-math3/3.1.1/commons-math3-3.1.1.jar:/root/.m2/repository/xmlenc/xmlenc/0.52/xmlenc-0.52.jar:/root/.m2/repository/commons-collections/commons-collections/3.2.1/commons-collections-3.2.1.jar:/root/.m2/repository/commons-el/commons-el/1.0/commons-el-1.0.jar:/root/.m2/repository/commons-logging/commons-logging/1.1.3/commons-logging-1.1.3.jar:/root/.m2/repository/commons-lang/commons-lang/2.6/commons-lang-2.6.jar:/root/.m2/repository/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar:/root/.m2/repository/commons-digester/commons-digester/1.8/commons-digester-1.8.jar:/root/.m2/repository/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar:/root/.m2/repository/commons-beanutils/commons-beanutils-core/1.8.0/commons-beanutils-core-1.8.0.jar:/root/.m2/repository/org/codehaus/jackson/jackson-core-asl/1.8.8/jackson-core-asl-1.8.8.jar:/root/.m2/repository/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-auth/2.3.0-cdh5.1.0/hadoop-auth-2.3.0-cdh5.1.0.jar:/root/.m2/repository/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar:/root/.m2/repository/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar:/root/.m2/repository/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar:/root/.m2/repository/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar:/root/.m2/repository/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar:/root/.m2/repository/com/jcraft/jsch/0.1.42/jsch-0.1.42.jar:/root/.m2/repository/org/apache/commons/commons-compress/1.4.1/commons-compress-1.4.1.jar:/root/.m2/repository/org/tukaani/xz/1.0/xz-1.0.jar:/root/.m2/repository/org/apache/hadoop/hadoop-hdfs/2.3.0-cdh5.1.0/hadoop-hdfs-2.3.0-cdh5.1.0.jar:/root/.m2/repository/com/sun/jersey/jersey-core/1.9/jersey-core-1.9.jar:/root/.m2/repository/com/sun/jersey/jersey-server/1.9/jersey-server-1.9.jar:/root/.m2/repository/org/apache/hadoop/hadoop-core/2.3.0-mr1-cdh5.1.0/hadoop-core-2.3.0-mr1-cdh5.1.0.jar:/root/.m2/repository/hsqldb/hsqldb/1.8.0.10/hsqldb-1.8.0.10.jar:/root/.m2/repository/log4j/log4j/1.2.17/log4j-1.2.17.jar:/root/.m2/repository/org/springframework/spring-context/3.0.5.RELEASE/spring-context-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-aop/3.0.5.RELEASE/spring-aop-3.0.5.RELEASE.jar:/root/.m2/repository/aopalliance/aopalliance/1.0/aopalliance-1.0.jar:/root/.m2/repository/org/springframework/spring-beans/3.0.5.RELEASE/spring-beans-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-core/3.0.5.RELEASE/spring-core-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-expression/3.0.5.RELEASE/spring-expression-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/spring-asm/3.0.5.RELEASE/spring-asm-3.0.5.RELEASE.jar:/root/.m2/repository/org/springframework/data/spring-data-hadoop/1.0.0.RELEASE/spring-data-hadoop-1.0.0.RELEASE.jar:/root/.m2/repository/org/apache/hadoop/hadoop-streaming/1.0.4/hadoop-streaming-1.0.4.jar:/root/.m2/repository/org/apache/hadoop/hadoop-tools/1.0.4/hadoop-tools-1.0.4.jar:/root/.m2/repository/org/springframework/spring-context-support/3.0.7.RELEASE/spring-context-support-3.0.7.RELEASE.jar:/root/.m2/repository/org/springframework/spring-jdbc/3.2.3.RELEASE/spring-jdbc-3.2.3.RELEASE.jar:/root/.m2/repository/org/springframework/spring-tx/3.2.3.RELEASE/spring-tx-3.2.3.RELEASE.jar:/root/.m2/repository/io/spray/spray-json_2.10/1.2.6/spray-json_2.10-1.2.6.jar:/root/.m2/repository/org/parboiled/parboiled-scala_2.10/1.1.6/parboiled-scala_2.10-1.1.6.jar:/root/.m2/repository/org/parboiled/parboiled-core/1.1.6/parboiled-core-1.1.6.jar:/root/.m2/repository/org/apache/spark/spark-sql_2.10/1.0.1/spark-sql_2.10-1.0.1.jar:/root/.m2/repository/org/apache/spark/spark-catalyst_2.10/1.0.1/spark-catalyst_2.10-1.0.1.jar:/root/.m2/repository/com/typesafe/scalalogging-slf4j_2.10/1.0.1/scalalogging-slf4j_2.10-1.0.1.jar:/root/.m2/repository/com/twitter/parquet-column/1.4.3/parquet-column-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-common/1.4.3/parquet-common-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-encoding/1.4.3/parquet-encoding-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-generator/1.4.3/parquet-generator-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-hadoop/1.4.3/parquet-hadoop-1.4.3.jar:/root/.m2/repository/com/twitter/parquet-format/2.0.0/parquet-format-2.0.0.jar:/root/.m2/repository/com/twitter/parquet-jackson/1.4.3/parquet-jackson-1.4.3.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-databind/2.3.0/jackson-databind-2.3.0.jar:/root/.m2/repository/com/fasterxml/jackson/core/jackson-core/2.3.0/jackson-core-2.3.0.jar:/root/.m2/repository/org/apache/spark/spark-hive_2.10/1.0.1/spark-hive_2.10-1.0.1.jar:/root/.m2/repository/org/spark-project/hive/hive-metastore/0.12.0/hive-metastore-0.12.0.jar:/root/.m2/repository/org/antlr/antlr/3.4/antlr-3.4.jar:/root/.m2/repository/org/antlr/antlr-runtime/3.4/antlr-runtime-3.4.jar:/root/.m2/repository/org/antlr/stringtemplate/3.2.1/stringtemplate-3.2.1.jar:/root/.m2/repository/antlr/antlr/2.7.7/antlr-2.7.7.jar:/root/.m2/repository/org/antlr/ST4/4.0.4/ST4-4.0.4.jar:/root/.m2/repository/com/jolbox/bonecp/0.7.1.RELEASE/bonecp-0.7.1.RELEASE.jar:/root/.m2/repository/commons-pool/commons-pool/1.5.4/commons-pool-1.5.4.jar:/root/.m2/repository/org/datanucleus/datanucleus-api-jdo/3.2.1/datanucleus-api-jdo-3.2.1.jar:/root/.m2/repository/org/datanucleus/datanucleus-core/3.2.2/datanucleus-core-3.2.2.jar:/root/.m2/repository/org/datanucleus/datanucleus-rdbms/3.2.1/datanucleus-rdbms-3.2.1.jar:/root/.m2/repository/javax/jdo/jdo-api/3.0.1/jdo-api-3.0.1.jar:/root/.m2/repository/javax/transaction/jta/1.1/jta-1.1.jar:/root/.m2/repository/org/apache/derby/derby/10.4.2.0/derby-10.4.2.0.jar:/root/.m2/repository/org/spark-project/hive/hive-exec/0.12.0/hive-exec-0.12.0.jar:/root/.m2/repository/org/iq80/snappy/snappy/0.2/snappy-0.2.jar:/root/.m2/repository/org/json/json/20090211/json-20090211.jar:/root/.m2/repository/com/googlecode/javaewah/JavaEWAH/0.3.2/JavaEWAH-0.3.2.jar:/root/.m2/repository/javolution/javolution/5.5.1/javolution-5.5.1.jar:/root/.m2/repository/jline/jline/0.9.94/jline-0.9.94.jar:/root/.m2/repository/org/codehaus/jackson/jackson-mapper-asl/1.8.8/jackson-mapper-asl-1.8.8.jar:/root/.m2/repository/org/spark-project/hive/hive-serde/0.12.0/hive-serde-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-common/0.12.0/hive-common-0.12.0.jar:/root/.m2/repository/org/spark-project/hive/hive-shims/0.12.0/hive-shims-0.12.0.jar:/root/.m2/repository/org/mockito/mockito-all/1.8.2/mockito-all-1.8.2.jar:/root/.m2/repository/org/apache/thrift/libfb303/0.9.0/libfb303-0.9.0.jar:/root/.m2/repository/org/apache/thrift/libthrift/0.9.0/libthrift-0.9.0.jar:/root/.m2/repository/org/apache/avro/avro-mapred/1.7.1/avro-mapred-1.7.1.jar:/root/.m2/repository/org/apache/avro/avro-ipc/1.7.1/avro-ipc-1.7.1.jar:/root/.m2/repository/org/mortbay/jetty/jetty/6.1.26/jetty-6.1.26.jar:/root/.m2/repository/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar:/root/.m2/repository/org/apache/velocity/velocity/1.7/velocity-1.7.jar:/root/.m2/repository/org/mortbay/jetty/servlet-api/2.5-20081211/servlet-api-2.5-20081211.jar:/root/.m2/repository/org/apache/avro/avro/1.7.6/avro-1.7.6.jar:/root/.m2/repository/com/thoughtworks/paranamer/paranamer/2.3/paranamer-2.3.jar
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:java.library.path=/usr/java/packages/lib/amd64:/usr/lib64:/lib64:/lib:/usr/lib
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:java.io.tmpdir=/tmp
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:java.compiler=<NA>
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:os.name=Linux
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:os.arch=amd64
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:os.version=3.8.0-26-generic
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:user.name=root
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:user.home=/root
2014-07-21 18:24:08 main ZooKeeper [INFO] Client environment:user.dir=/home/ema/work/jawsGit/http-spark-sql-server/test-project
2014-07-21 18:24:08 main ZooKeeper [INFO] Initiating client connection, connectString=10.0.2.16,10.0.2.18,10.0.2.17:2181 sessionTimeout=600000 watcher=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager$DummyWatcher@5f959f30
2014-07-21 18:24:08 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Opening socket connection to server ip-10-0-2-17/10.0.2.17:2181. Will not attempt to authenticate using SASL (unknown error)
2014-07-21 18:24:08 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Socket connection established to ip-10-0-2-17/10.0.2.17:2181, initiating session
2014-07-21 18:24:08 main-SendThread(ip-10-0-2-17:2181) ClientCnxn [INFO] Session establishment complete on server ip-10-0-2-17/10.0.2.17:2181, sessionid = 0x34758d19e5d0104, negotiated timeout = 40000
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=acquireReadWriteLocks>
2014-07-21 18:24:08 main Driver [INFO] </PERFLOG method=acquireReadWriteLocks start=1405956248637 end=1405956248638 duration=1>
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=Driver.execute>
2014-07-21 18:24:08 main Driver [INFO] Starting command: show databases
2014-07-21 18:24:08 main Driver [INFO] </PERFLOG method=TimeToSubmit start=1405956248065 end=1405956248653 duration=588>
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=runTasks>
2014-07-21 18:24:08 main Driver [INFO] <PERFLOG method=task.DDL.Stage-0>
2014-07-21 18:24:08 main metastore [INFO] Trying to connect to metastore with URI thrift://10.0.2.16:9083
2014-07-21 18:24:08 main metastore [INFO] Waiting 1 seconds before next connection attempt.
2014-07-21 18:24:09 main metastore [INFO] Connected to metastore.
2014-07-21 18:24:10 main DDLTask [INFO] results : 1
2014-07-21 18:24:10 main Driver [INFO] </PERFLOG method=task.DDL.Stage-0 start=1405956248653 end=1405956250141 duration=1488>
2014-07-21 18:24:10 main Driver [INFO] </PERFLOG method=runTasks start=1405956248653 end=1405956250141 duration=1488>
2014-07-21 18:24:10 main Driver [INFO] </PERFLOG method=Driver.execute start=1405956248638 end=1405956250141 duration=1503>
2014-07-21 18:24:10 main Driver [INFO] OK
2014-07-21 18:24:10 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:24:10 main Driver [INFO] </PERFLOG method=releaseLocks start=1405956250143 end=1405956250143 duration=0>
2014-07-21 18:24:10 main Driver [INFO] </PERFLOG method=Driver.run start=1405956248065 end=1405956250143 duration=2078>
2014-07-21 18:24:10 main FileInputFormat [INFO] Total input paths to process : 1
2014-07-21 18:24:10 main Driver [INFO] <PERFLOG method=releaseLocks>
2014-07-21 18:24:10 main Driver [INFO] </PERFLOG method=releaseLocks start=1405956250181 end=1405956250181 duration=0>
2014-07-21 18:24:10 main ZooKeeper [INFO] Session: 0x34758d19e5d0104 closed
2014-07-21 18:24:10 main-EventThread ClientCnxn [INFO] EventThread shut down
2014-07-21 18:24:10 main SparkContext [INFO] Starting job: collect at SparkPlan.scala:52
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Got job 0 (collect at SparkPlan.scala:52) with 1 output partitions (allowLocal=false)
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Final stage: Stage 0(collect at SparkPlan.scala:52)
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Parents of final stage: List()
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Missing parents: List()
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Submitting Stage 0 (MappedRDD[4] at map at SparkPlan.scala:52), which has no missing parents
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 DAGScheduler [INFO] Submitting 1 missing tasks from Stage 0 (MappedRDD[4] at map at SparkPlan.scala:52)
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 TaskSchedulerImpl [INFO] Adding task set 0.0 with 1 tasks
2014-07-21 18:24:10 spark-akka.actor.default-dispatcher-3 FairSchedulableBuilder [INFO] Added task set TaskSet_0 tasks to pool default
2014-07-21 18:24:25 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:24:40 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:24:55 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:25:10 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721152409-0007/0 is now EXITED (Command exited with code 1)
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-4 SparkDeploySchedulerBackend [INFO] Executor app-20140721152409-0007/0 removed: Command exited with code 1
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor added: app-20140721152409-0007/2 on worker-20140721144118-ip-10-0-2-17.ec2.internal-54536 (ip-10-0-2-17.ec2.internal:54536) with 1 cores
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-2 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721152409-0007/2 on hostPort ip-10-0-2-17.ec2.internal:54536 with 1 cores, 2.0 GB RAM
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721152409-0007/2 is now RUNNING
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor updated: app-20140721152409-0007/1 is now EXITED (Command exited with code 1)
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-2 SparkDeploySchedulerBackend [INFO] Executor app-20140721152409-0007/1 removed: Command exited with code 1
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-2 AppClient$ClientActor [INFO] Executor added: app-20140721152409-0007/3 on worker-20140721144118-ip-10-0-2-18.ec2.internal-59879 (ip-10-0-2-18.ec2.internal:59879) with 1 cores
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-2 SparkDeploySchedulerBackend [INFO] Granted executor ID app-20140721152409-0007/3 on hostPort ip-10-0-2-18.ec2.internal:59879 with 1 cores, 2.0 GB RAM
2014-07-21 18:25:14 spark-akka.actor.default-dispatcher-4 AppClient$ClientActor [INFO] Executor updated: app-20140721152409-0007/3 is now RUNNING
2014-07-21 18:25:25 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:25:40 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
2014-07-21 18:25:55 Timer-0 TaskSchedulerImpl [WARN] Initial job has not accepted any resources; check your cluster UI to ensure that workers are registered and have sufficient memory
